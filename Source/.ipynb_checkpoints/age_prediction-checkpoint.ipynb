{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1305              NaN     1.0       NaN    0.0  0.000000  0.015713     0.0   \n",
       "1306              NaN     0.0  0.484795    0.0  0.000000  0.212559     1.0   \n",
       "1307              NaN     1.0  0.478512    0.0  0.000000  0.014151     0.0   \n",
       "1308              NaN     1.0       NaN    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0       NaN    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  STON/O  W./C.  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0     1.0    0.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...     ...    ...  ...  ...   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1306          0.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1307          1.0  0.0  0.0  ...         1.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1306              0.0   0.0  0.0   0.0  \n",
       "1307              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[1309 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "normalized_data = pd.read_csv(\"../Output/normalized_data.csv\", index_col=0)\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Survived', 418),\n",
       " ('Age', 263),\n",
       " ('Pclass', 0),\n",
       " ('SibSp', 0),\n",
       " ('Parch', 0),\n",
       " ('Fare', 0),\n",
       " ('female', 0),\n",
       " ('male', 0),\n",
       " ('C', 0),\n",
       " ('Q', 0),\n",
       " ('S', 0),\n",
       " ('Mr', 0),\n",
       " ('Miss', 0),\n",
       " ('Mrs', 0),\n",
       " ('PC', 0),\n",
       " ('C.A.', 0),\n",
       " ('SOTON/O.Q.', 0),\n",
       " ('2.', 0),\n",
       " ('STON/O', 0),\n",
       " ('W./C.', 0),\n",
       " ('CA.', 0),\n",
       " ('A/5', 0),\n",
       " ('SC/PARIS', 0),\n",
       " ('2343', 0),\n",
       " ('CA', 0),\n",
       " ('A/5.', 0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_values = [(label, normalized_data[label].isnull().sum()) for label in normalized_data.columns.values]\n",
    "sorted(empty_values, reverse=True, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate samples with and without age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_with_age = normalized_data[normalized_data.Age.notna()]\n",
    "samples_without_age = normalized_data[normalized_data.Age.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model for age prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 240us/step - loss: 0.0362 - mae: 0.1476 - val_loss: 0.0282 - val_mae: 0.1277\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0263 - mae: 0.1260 - val_loss: 0.0257 - val_mae: 0.1263\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0241 - mae: 0.1200 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0229 - mae: 0.1172 - val_loss: 0.0247 - val_mae: 0.1243\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0221 - mae: 0.1150 - val_loss: 0.0246 - val_mae: 0.1175\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0218 - mae: 0.1132 - val_loss: 0.0227 - val_mae: 0.1146\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0212 - mae: 0.1129 - val_loss: 0.0231 - val_mae: 0.1151\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0208 - mae: 0.1104 - val_loss: 0.0233 - val_mae: 0.1206\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0204 - mae: 0.1102 - val_loss: 0.0231 - val_mae: 0.1190\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 173us/step - loss: 0.0202 - mae: 0.1099 - val_loss: 0.0239 - val_mae: 0.1173\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 194us/step - loss: 0.0200 - mae: 0.1092 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0199 - mae: 0.1087 - val_loss: 0.0221 - val_mae: 0.1145\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0196 - mae: 0.1069 - val_loss: 0.0217 - val_mae: 0.1128\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0195 - mae: 0.1063 - val_loss: 0.0227 - val_mae: 0.1187\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0192 - mae: 0.1061 - val_loss: 0.0217 - val_mae: 0.1141\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0191 - mae: 0.1058 - val_loss: 0.0224 - val_mae: 0.1113\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0189 - mae: 0.1051 - val_loss: 0.0224 - val_mae: 0.1124\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0190 - mae: 0.1046 - val_loss: 0.0221 - val_mae: 0.1163\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0188 - mae: 0.1046 - val_loss: 0.0226 - val_mae: 0.1178\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 224us/step - loss: 0.0189 - mae: 0.1052 - val_loss: 0.0214 - val_mae: 0.1113\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0186 - mae: 0.1046 - val_loss: 0.0213 - val_mae: 0.1104\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 142us/step - loss: 0.0185 - mae: 0.1041 - val_loss: 0.0212 - val_mae: 0.1110\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0182 - mae: 0.1030 - val_loss: 0.0211 - val_mae: 0.1116\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 204us/step - loss: 0.0182 - mae: 0.1029 - val_loss: 0.0216 - val_mae: 0.1130\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 158us/step - loss: 0.0183 - mae: 0.1030 - val_loss: 0.0233 - val_mae: 0.1208\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 179us/step - loss: 0.0180 - mae: 0.1030 - val_loss: 0.0206 - val_mae: 0.1097\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0180 - mae: 0.1018 - val_loss: 0.0207 - val_mae: 0.1094\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 152us/step - loss: 0.0179 - mae: 0.1017 - val_loss: 0.0211 - val_mae: 0.1089\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 148us/step - loss: 0.0178 - mae: 0.1019 - val_loss: 0.0216 - val_mae: 0.1105\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0179 - mae: 0.1018 - val_loss: 0.0207 - val_mae: 0.1083\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0176 - mae: 0.1006 - val_loss: 0.0211 - val_mae: 0.1117\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0178 - mae: 0.1008 - val_loss: 0.0211 - val_mae: 0.1092\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0177 - mae: 0.0998 - val_loss: 0.0210 - val_mae: 0.1095\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0177 - mae: 0.1012 - val_loss: 0.0210 - val_mae: 0.1098\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0177 - mae: 0.1011 - val_loss: 0.0208 - val_mae: 0.1090\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.1002 - val_loss: 0.0205 - val_mae: 0.1079\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0174 - mae: 0.1008 - val_loss: 0.0212 - val_mae: 0.1080\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.1001 - val_loss: 0.0203 - val_mae: 0.1074\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0172 - mae: 0.0987 - val_loss: 0.0211 - val_mae: 0.1097\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0996 - val_loss: 0.0213 - val_mae: 0.1100\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0174 - mae: 0.0998 - val_loss: 0.0207 - val_mae: 0.1076\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0174 - mae: 0.0998 - val_loss: 0.0209 - val_mae: 0.1101\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 195us/step - loss: 0.0173 - mae: 0.0998 - val_loss: 0.0206 - val_mae: 0.1078\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 150us/step - loss: 0.0172 - mae: 0.0989 - val_loss: 0.0214 - val_mae: 0.1092\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0173 - mae: 0.0995 - val_loss: 0.0208 - val_mae: 0.1075\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0996 - val_loss: 0.0208 - val_mae: 0.1086\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0170 - mae: 0.0988 - val_loss: 0.0207 - val_mae: 0.1075\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0168 - mae: 0.0980 - val_loss: 0.0225 - val_mae: 0.1114\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0172 - mae: 0.0987 - val_loss: 0.0203 - val_mae: 0.1064\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0170 - mae: 0.0983 - val_loss: 0.0208 - val_mae: 0.1111\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0169 - mae: 0.0980 - val_loss: 0.0204 - val_mae: 0.1067\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0170 - mae: 0.0992 - val_loss: 0.0203 - val_mae: 0.1068\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0169 - mae: 0.0980 - val_loss: 0.0204 - val_mae: 0.1070\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0981 - val_loss: 0.0206 - val_mae: 0.1074\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 145us/step - loss: 0.0169 - mae: 0.0979 - val_loss: 0.0208 - val_mae: 0.1089\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0167 - mae: 0.0975 - val_loss: 0.0205 - val_mae: 0.1075\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 156us/step - loss: 0.0169 - mae: 0.0984 - val_loss: 0.0208 - val_mae: 0.1094\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0168 - mae: 0.0982 - val_loss: 0.0216 - val_mae: 0.1099\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0169 - mae: 0.0977 - val_loss: 0.0204 - val_mae: 0.1070\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0165 - mae: 0.0964 - val_loss: 0.0211 - val_mae: 0.1090\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 113us/step - loss: 0.0167 - mae: 0.0974 - val_loss: 0.0216 - val_mae: 0.1094\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 215us/step - loss: 0.0168 - mae: 0.0971 - val_loss: 0.0203 - val_mae: 0.1071\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0963 - val_loss: 0.0206 - val_mae: 0.1085\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0982 - val_loss: 0.0204 - val_mae: 0.1061\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0166 - mae: 0.0970 - val_loss: 0.0212 - val_mae: 0.1123\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0165 - mae: 0.0970 - val_loss: 0.0206 - val_mae: 0.1063\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0166 - mae: 0.0974 - val_loss: 0.0201 - val_mae: 0.1055\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0165 - mae: 0.0968 - val_loss: 0.0209 - val_mae: 0.1087\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 170us/step - loss: 0.0166 - mae: 0.0970 - val_loss: 0.0212 - val_mae: 0.1083\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0162 - mae: 0.0961 - val_loss: 0.0203 - val_mae: 0.1077\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0164 - mae: 0.0969 - val_loss: 0.0205 - val_mae: 0.1074\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0162 - mae: 0.0965 - val_loss: 0.0204 - val_mae: 0.1093\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 198us/step - loss: 0.0162 - mae: 0.0960 - val_loss: 0.0222 - val_mae: 0.1104\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 141us/step - loss: 0.0162 - mae: 0.0963 - val_loss: 0.0212 - val_mae: 0.1117\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0162 - mae: 0.0958 - val_loss: 0.0208 - val_mae: 0.1098\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0161 - mae: 0.0957 - val_loss: 0.0205 - val_mae: 0.1074\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0161 - mae: 0.0956 - val_loss: 0.0209 - val_mae: 0.1082\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0161 - mae: 0.0954 - val_loss: 0.0210 - val_mae: 0.1089\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0161 - mae: 0.0965 - val_loss: 0.0203 - val_mae: 0.1074\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0160 - mae: 0.0952 - val_loss: 0.0208 - val_mae: 0.1088\n",
      "processing fold # 1\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 219us/step - loss: 0.0495 - mae: 0.1698 - val_loss: 0.0293 - val_mae: 0.1339\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0268 - mae: 0.1266 - val_loss: 0.0260 - val_mae: 0.1250\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 171us/step - loss: 0.0237 - mae: 0.1206 - val_loss: 0.0243 - val_mae: 0.1192\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 145us/step - loss: 0.0222 - mae: 0.1170 - val_loss: 0.0230 - val_mae: 0.1148\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 151us/step - loss: 0.0218 - mae: 0.1158 - val_loss: 0.0234 - val_mae: 0.1141\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0212 - mae: 0.1142 - val_loss: 0.0242 - val_mae: 0.1243\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0210 - mae: 0.1138 - val_loss: 0.0229 - val_mae: 0.1171\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0207 - mae: 0.1119 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0206 - mae: 0.1125 - val_loss: 0.0256 - val_mae: 0.1166\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 164us/step - loss: 0.0203 - mae: 0.1109 - val_loss: 0.0228 - val_mae: 0.1131\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0202 - mae: 0.1113 - val_loss: 0.0230 - val_mae: 0.1168\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0199 - mae: 0.1105 - val_loss: 0.0244 - val_mae: 0.1249\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0200 - mae: 0.1100 - val_loss: 0.0223 - val_mae: 0.1167\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0197 - mae: 0.1091 - val_loss: 0.0237 - val_mae: 0.1139\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0197 - mae: 0.1091 - val_loss: 0.0240 - val_mae: 0.1141\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0196 - mae: 0.1089 - val_loss: 0.0228 - val_mae: 0.1142\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0193 - mae: 0.1082 - val_loss: 0.0219 - val_mae: 0.1120\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0193 - mae: 0.1087 - val_loss: 0.0225 - val_mae: 0.1172\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0193 - mae: 0.1082 - val_loss: 0.0222 - val_mae: 0.1122\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0191 - mae: 0.1071 - val_loss: 0.0220 - val_mae: 0.1125\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0188 - mae: 0.1074 - val_loss: 0.0232 - val_mae: 0.1214\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0192 - mae: 0.1082 - val_loss: 0.0217 - val_mae: 0.1136\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0190 - mae: 0.1064 - val_loss: 0.0230 - val_mae: 0.1190\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 139us/step - loss: 0.0188 - mae: 0.1063 - val_loss: 0.0221 - val_mae: 0.1142\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0189 - mae: 0.1065 - val_loss: 0.0223 - val_mae: 0.1163\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0188 - mae: 0.1063 - val_loss: 0.0217 - val_mae: 0.1106\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0187 - mae: 0.1056 - val_loss: 0.0238 - val_mae: 0.1161\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 143us/step - loss: 0.0186 - mae: 0.1055 - val_loss: 0.0216 - val_mae: 0.1117\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0186 - mae: 0.1059 - val_loss: 0.0212 - val_mae: 0.1109\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0186 - mae: 0.1053 - val_loss: 0.0214 - val_mae: 0.1128\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.1046 - val_loss: 0.0216 - val_mae: 0.1103\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0183 - mae: 0.1049 - val_loss: 0.0226 - val_mae: 0.1177\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0184 - mae: 0.1053 - val_loss: 0.0220 - val_mae: 0.1102\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0181 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0185 - mae: 0.1048 - val_loss: 0.0227 - val_mae: 0.1120\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.1034 - val_loss: 0.0211 - val_mae: 0.1089\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0181 - mae: 0.1035 - val_loss: 0.0218 - val_mae: 0.1093\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.1022 - val_loss: 0.0211 - val_mae: 0.1086\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.1029 - val_loss: 0.0211 - val_mae: 0.1102\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.1026 - val_loss: 0.0211 - val_mae: 0.1077\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 125us/step - loss: 0.0177 - mae: 0.1019 - val_loss: 0.0216 - val_mae: 0.1149\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0179 - mae: 0.1035 - val_loss: 0.0215 - val_mae: 0.1107\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.1027 - val_loss: 0.0210 - val_mae: 0.1095\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 174us/step - loss: 0.0176 - mae: 0.1027 - val_loss: 0.0221 - val_mae: 0.1099\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 184us/step - loss: 0.0176 - mae: 0.1022 - val_loss: 0.0213 - val_mae: 0.1101\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 135us/step - loss: 0.0176 - mae: 0.1022 - val_loss: 0.0209 - val_mae: 0.1093\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.1022 - val_loss: 0.0210 - val_mae: 0.1108\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0176 - mae: 0.1019 - val_loss: 0.0212 - val_mae: 0.1098\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0174 - mae: 0.1012 - val_loss: 0.0218 - val_mae: 0.1096\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0177 - mae: 0.1018 - val_loss: 0.0211 - val_mae: 0.1103\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.1022 - val_loss: 0.0215 - val_mae: 0.1136\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.1001 - val_loss: 0.0211 - val_mae: 0.1134\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 165us/step - loss: 0.0175 - mae: 0.1014 - val_loss: 0.0211 - val_mae: 0.1097\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 138us/step - loss: 0.0173 - mae: 0.1008 - val_loss: 0.0208 - val_mae: 0.1086\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.1018 - val_loss: 0.0224 - val_mae: 0.1174\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.1011 - val_loss: 0.0215 - val_mae: 0.1133\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0174 - mae: 0.1014 - val_loss: 0.0206 - val_mae: 0.1086\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0173 - mae: 0.1012 - val_loss: 0.0223 - val_mae: 0.1175\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0172 - mae: 0.1006 - val_loss: 0.0204 - val_mae: 0.1072\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0171 - mae: 0.1003 - val_loss: 0.0211 - val_mae: 0.1091\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0173 - mae: 0.1005 - val_loss: 0.0215 - val_mae: 0.1092\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0170 - mae: 0.0995 - val_loss: 0.0203 - val_mae: 0.1079\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0172 - mae: 0.1010 - val_loss: 0.0209 - val_mae: 0.1097\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0171 - mae: 0.1012 - val_loss: 0.0215 - val_mae: 0.1128\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.1003 - val_loss: 0.0211 - val_mae: 0.1087\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0169 - mae: 0.0996 - val_loss: 0.0202 - val_mae: 0.1067\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0166 - mae: 0.0984 - val_loss: 0.0211 - val_mae: 0.1120\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0169 - mae: 0.0996 - val_loss: 0.0219 - val_mae: 0.1107\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0169 - mae: 0.0991 - val_loss: 0.0206 - val_mae: 0.1083\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0170 - mae: 0.0995 - val_loss: 0.0208 - val_mae: 0.1102\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0168 - mae: 0.0987 - val_loss: 0.0202 - val_mae: 0.1076\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0167 - mae: 0.0998 - val_loss: 0.0212 - val_mae: 0.1080\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0985 - val_loss: 0.0200 - val_mae: 0.1065\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0167 - mae: 0.0995 - val_loss: 0.0201 - val_mae: 0.1058\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0167 - mae: 0.0988 - val_loss: 0.0211 - val_mae: 0.1126\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0166 - mae: 0.0984 - val_loss: 0.0206 - val_mae: 0.1118\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0167 - mae: 0.0988 - val_loss: 0.0212 - val_mae: 0.1069\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0167 - mae: 0.0979 - val_loss: 0.0211 - val_mae: 0.1140\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 145us/step - loss: 0.0166 - mae: 0.0989 - val_loss: 0.0210 - val_mae: 0.1122\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 139us/step - loss: 0.0166 - mae: 0.0990 - val_loss: 0.0210 - val_mae: 0.1086\n",
      "processing fold # 2\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 219us/step - loss: 0.0787 - mae: 0.2160 - val_loss: 0.0373 - val_mae: 0.1475\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0310 - mae: 0.1350 - val_loss: 0.0283 - val_mae: 0.1325\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0249 - mae: 0.1220 - val_loss: 0.0282 - val_mae: 0.1304\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0231 - mae: 0.1175 - val_loss: 0.0265 - val_mae: 0.1292\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0220 - mae: 0.1141 - val_loss: 0.0286 - val_mae: 0.1393\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0213 - mae: 0.1122 - val_loss: 0.0307 - val_mae: 0.1319\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0209 - mae: 0.1112 - val_loss: 0.0272 - val_mae: 0.1289\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 234us/step - loss: 0.0204 - mae: 0.1094 - val_loss: 0.0266 - val_mae: 0.1287\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 200us/step - loss: 0.0199 - mae: 0.1089 - val_loss: 0.0268 - val_mae: 0.1291\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0197 - mae: 0.1079 - val_loss: 0.0269 - val_mae: 0.1285\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0195 - mae: 0.1068 - val_loss: 0.0271 - val_mae: 0.1277\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0192 - mae: 0.1059 - val_loss: 0.0263 - val_mae: 0.1271\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0190 - mae: 0.1051 - val_loss: 0.0257 - val_mae: 0.1270\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0188 - mae: 0.1052 - val_loss: 0.0287 - val_mae: 0.1276\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0187 - mae: 0.1049 - val_loss: 0.0258 - val_mae: 0.1260\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0186 - mae: 0.1037 - val_loss: 0.0272 - val_mae: 0.1270\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0184 - mae: 0.1038 - val_loss: 0.0260 - val_mae: 0.1260\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.1031 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0181 - mae: 0.1024 - val_loss: 0.0259 - val_mae: 0.1267\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 234us/step - loss: 0.0182 - mae: 0.1025 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 176us/step - loss: 0.0180 - mae: 0.1021 - val_loss: 0.0261 - val_mae: 0.1251\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0180 - mae: 0.1017 - val_loss: 0.0277 - val_mae: 0.1271\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0178 - mae: 0.1007 - val_loss: 0.0248 - val_mae: 0.1256\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0180 - mae: 0.1013 - val_loss: 0.0247 - val_mae: 0.1267\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 181us/step - loss: 0.0176 - mae: 0.1009 - val_loss: 0.0245 - val_mae: 0.1250\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0174 - mae: 0.1001 - val_loss: 0.0251 - val_mae: 0.1244\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0174 - mae: 0.1000 - val_loss: 0.0245 - val_mae: 0.1257\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0996 - val_loss: 0.0254 - val_mae: 0.1233\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0998 - val_loss: 0.0247 - val_mae: 0.1290\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0174 - mae: 0.0990 - val_loss: 0.0245 - val_mae: 0.1277\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0174 - mae: 0.0998 - val_loss: 0.0248 - val_mae: 0.1237\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0172 - mae: 0.0987 - val_loss: 0.0249 - val_mae: 0.1233\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0168 - mae: 0.0976 - val_loss: 0.0254 - val_mae: 0.1323\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0169 - mae: 0.0987 - val_loss: 0.0238 - val_mae: 0.1229\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0992 - val_loss: 0.0256 - val_mae: 0.1238\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0169 - mae: 0.0989 - val_loss: 0.0242 - val_mae: 0.1214\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0170 - mae: 0.0982 - val_loss: 0.0240 - val_mae: 0.1208\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 185us/step - loss: 0.0168 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1214\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0168 - mae: 0.0984 - val_loss: 0.0243 - val_mae: 0.1211\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0168 - mae: 0.0974 - val_loss: 0.0241 - val_mae: 0.1262\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0168 - mae: 0.0978 - val_loss: 0.0253 - val_mae: 0.1216\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 162us/step - loss: 0.0168 - mae: 0.0975 - val_loss: 0.0238 - val_mae: 0.1219\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0166 - mae: 0.0971 - val_loss: 0.0251 - val_mae: 0.1213\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 107us/step - loss: 0.0164 - mae: 0.0972 - val_loss: 0.0243 - val_mae: 0.1215\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0167 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1214\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 144us/step - loss: 0.0163 - mae: 0.0965 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0166 - mae: 0.0966 - val_loss: 0.0235 - val_mae: 0.1225\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0960 - val_loss: 0.0264 - val_mae: 0.1214\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 182us/step - loss: 0.0166 - mae: 0.0975 - val_loss: 0.0243 - val_mae: 0.1210\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0166 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1215\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 138us/step - loss: 0.0162 - mae: 0.0963 - val_loss: 0.0241 - val_mae: 0.1209\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 158us/step - loss: 0.0164 - mae: 0.0953 - val_loss: 0.0270 - val_mae: 0.1228\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0163 - mae: 0.0967 - val_loss: 0.0240 - val_mae: 0.1206\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 137us/step - loss: 0.0163 - mae: 0.0961 - val_loss: 0.0233 - val_mae: 0.1209\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 158us/step - loss: 0.0164 - mae: 0.0965 - val_loss: 0.0235 - val_mae: 0.1194\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 104us/step - loss: 0.0162 - mae: 0.0959 - val_loss: 0.0232 - val_mae: 0.1209\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0163 - mae: 0.0957 - val_loss: 0.0230 - val_mae: 0.1234\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 177us/step - loss: 0.0163 - mae: 0.0961 - val_loss: 0.0232 - val_mae: 0.1233\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0163 - mae: 0.0963 - val_loss: 0.0227 - val_mae: 0.1195\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0160 - mae: 0.0950 - val_loss: 0.0270 - val_mae: 0.1221\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0162 - mae: 0.0952 - val_loss: 0.0232 - val_mae: 0.1211\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0964 - val_loss: 0.0238 - val_mae: 0.1184\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0160 - mae: 0.0953 - val_loss: 0.0231 - val_mae: 0.1189\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0159 - mae: 0.0948 - val_loss: 0.0234 - val_mae: 0.1185\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 162us/step - loss: 0.0160 - mae: 0.0952 - val_loss: 0.0243 - val_mae: 0.1192\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0160 - mae: 0.0946 - val_loss: 0.0232 - val_mae: 0.1197\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0159 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1185\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0160 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1224\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0160 - mae: 0.0947 - val_loss: 0.0227 - val_mae: 0.1201\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0158 - mae: 0.0938 - val_loss: 0.0240 - val_mae: 0.1185\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0160 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1200\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0159 - mae: 0.0943 - val_loss: 0.0227 - val_mae: 0.1199\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0158 - mae: 0.0951 - val_loss: 0.0230 - val_mae: 0.1178\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0158 - mae: 0.0947 - val_loss: 0.0246 - val_mae: 0.1189\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0158 - mae: 0.0940 - val_loss: 0.0238 - val_mae: 0.1178\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0157 - mae: 0.0933 - val_loss: 0.0226 - val_mae: 0.1173\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0158 - mae: 0.0939 - val_loss: 0.0226 - val_mae: 0.1188\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 137us/step - loss: 0.0157 - mae: 0.0944 - val_loss: 0.0231 - val_mae: 0.1181\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0156 - mae: 0.0942 - val_loss: 0.0229 - val_mae: 0.1192\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0155 - mae: 0.0940 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "processing fold # 3\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 247us/step - loss: 0.0910 - mae: 0.2364 - val_loss: 0.0365 - val_mae: 0.1411\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0310 - mae: 0.1338 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0257 - mae: 0.1224 - val_loss: 0.0233 - val_mae: 0.1129\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0240 - mae: 0.1189 - val_loss: 0.0215 - val_mae: 0.1089\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0229 - mae: 0.1167 - val_loss: 0.0209 - val_mae: 0.1067\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0222 - mae: 0.1149 - val_loss: 0.0204 - val_mae: 0.1059\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0215 - mae: 0.1128 - val_loss: 0.0202 - val_mae: 0.1093\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0212 - mae: 0.1131 - val_loss: 0.0202 - val_mae: 0.1111\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0210 - mae: 0.1127 - val_loss: 0.0199 - val_mae: 0.1067\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 185us/step - loss: 0.0207 - mae: 0.1121 - val_loss: 0.0203 - val_mae: 0.1124\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0205 - mae: 0.1118 - val_loss: 0.0198 - val_mae: 0.1062\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0202 - mae: 0.1104 - val_loss: 0.0201 - val_mae: 0.1111\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 173us/step - loss: 0.0200 - mae: 0.1094 - val_loss: 0.0206 - val_mae: 0.1129\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0200 - mae: 0.1098 - val_loss: 0.0204 - val_mae: 0.1123\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0198 - mae: 0.1092 - val_loss: 0.0199 - val_mae: 0.1076\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0197 - mae: 0.1091 - val_loss: 0.0199 - val_mae: 0.1081\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0197 - mae: 0.1086 - val_loss: 0.0203 - val_mae: 0.1122\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0195 - mae: 0.1083 - val_loss: 0.0206 - val_mae: 0.1138\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 197us/step - loss: 0.0193 - mae: 0.1078 - val_loss: 0.0198 - val_mae: 0.1078\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0193 - mae: 0.1079 - val_loss: 0.0196 - val_mae: 0.1070\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0191 - mae: 0.1076 - val_loss: 0.0199 - val_mae: 0.1049\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0190 - mae: 0.1066 - val_loss: 0.0210 - val_mae: 0.1147\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0191 - mae: 0.1075 - val_loss: 0.0197 - val_mae: 0.1066\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.1052 - val_loss: 0.0201 - val_mae: 0.1078\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0189 - mae: 0.1062 - val_loss: 0.0196 - val_mae: 0.1069\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0187 - mae: 0.1053 - val_loss: 0.0199 - val_mae: 0.1086\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0187 - mae: 0.1061 - val_loss: 0.0198 - val_mae: 0.1077\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0185 - mae: 0.1044 - val_loss: 0.0196 - val_mae: 0.1038\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.1051 - val_loss: 0.0195 - val_mae: 0.1047\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0183 - mae: 0.1048 - val_loss: 0.0204 - val_mae: 0.1049\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0185 - mae: 0.1039 - val_loss: 0.0204 - val_mae: 0.1118\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0185 - mae: 0.1045 - val_loss: 0.0196 - val_mae: 0.1062\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0182 - mae: 0.1039 - val_loss: 0.0196 - val_mae: 0.1087\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0182 - mae: 0.1040 - val_loss: 0.0197 - val_mae: 0.1079\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.1040 - val_loss: 0.0204 - val_mae: 0.1057\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0182 - mae: 0.1037 - val_loss: 0.0195 - val_mae: 0.1076\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0180 - mae: 0.1035 - val_loss: 0.0192 - val_mae: 0.1044\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 141us/step - loss: 0.0180 - mae: 0.1030 - val_loss: 0.0196 - val_mae: 0.1053\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 135us/step - loss: 0.0179 - mae: 0.1037 - val_loss: 0.0194 - val_mae: 0.1060\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 139us/step - loss: 0.0177 - mae: 0.1027 - val_loss: 0.0195 - val_mae: 0.1037\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0178 - mae: 0.1028 - val_loss: 0.0192 - val_mae: 0.1046\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.1019 - val_loss: 0.0204 - val_mae: 0.1026\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0178 - mae: 0.1025 - val_loss: 0.0192 - val_mae: 0.1058\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0177 - mae: 0.1025 - val_loss: 0.0196 - val_mae: 0.1052\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 137us/step - loss: 0.0177 - mae: 0.1024 - val_loss: 0.0195 - val_mae: 0.1075\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 161us/step - loss: 0.0176 - mae: 0.1028 - val_loss: 0.0195 - val_mae: 0.1040\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0176 - mae: 0.1027 - val_loss: 0.0193 - val_mae: 0.1058\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.1013 - val_loss: 0.0193 - val_mae: 0.1049\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0175 - mae: 0.1014 - val_loss: 0.0201 - val_mae: 0.1029\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0175 - mae: 0.1012 - val_loss: 0.0193 - val_mae: 0.1034\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0174 - mae: 0.1011 - val_loss: 0.0194 - val_mae: 0.1038\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0173 - mae: 0.1013 - val_loss: 0.0194 - val_mae: 0.1072\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0173 - mae: 0.1010 - val_loss: 0.0198 - val_mae: 0.1099\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.1008 - val_loss: 0.0193 - val_mae: 0.1036\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0174 - mae: 0.1014 - val_loss: 0.0195 - val_mae: 0.1052\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0173 - mae: 0.1009 - val_loss: 0.0195 - val_mae: 0.1037\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0173 - mae: 0.1013 - val_loss: 0.0196 - val_mae: 0.1031\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0171 - mae: 0.1005 - val_loss: 0.0194 - val_mae: 0.1059\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.1011 - val_loss: 0.0192 - val_mae: 0.1068\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0170 - mae: 0.1003 - val_loss: 0.0194 - val_mae: 0.1046\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0170 - mae: 0.1003 - val_loss: 0.0193 - val_mae: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.1003 - val_loss: 0.0191 - val_mae: 0.1054\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0169 - mae: 0.0996 - val_loss: 0.0198 - val_mae: 0.1100\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0170 - mae: 0.1002 - val_loss: 0.0192 - val_mae: 0.1065\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0170 - mae: 0.0999 - val_loss: 0.0195 - val_mae: 0.1094\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0170 - mae: 0.1006 - val_loss: 0.0196 - val_mae: 0.1041\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0167 - mae: 0.0996 - val_loss: 0.0199 - val_mae: 0.1031\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0168 - mae: 0.0992 - val_loss: 0.0196 - val_mae: 0.1041\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0996 - val_loss: 0.0209 - val_mae: 0.1064\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0168 - mae: 0.0994 - val_loss: 0.0195 - val_mae: 0.1045\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0169 - mae: 0.0998 - val_loss: 0.0195 - val_mae: 0.1085\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 139us/step - loss: 0.0167 - mae: 0.0997 - val_loss: 0.0203 - val_mae: 0.1047\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0167 - mae: 0.0991 - val_loss: 0.0194 - val_mae: 0.1043\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0166 - mae: 0.0995 - val_loss: 0.0194 - val_mae: 0.1052\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0169 - mae: 0.0996 - val_loss: 0.0192 - val_mae: 0.1062\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0166 - mae: 0.0991 - val_loss: 0.0196 - val_mae: 0.1086\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0167 - mae: 0.0995 - val_loss: 0.0194 - val_mae: 0.1064\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0166 - mae: 0.0984 - val_loss: 0.0194 - val_mae: 0.1075\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0165 - mae: 0.0989 - val_loss: 0.0195 - val_mae: 0.1049\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0166 - mae: 0.0983 - val_loss: 0.0199 - val_mae: 0.1105\n",
      "processing fold # 4\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 224us/step - loss: 0.0375 - mae: 0.1522 - val_loss: 0.0251 - val_mae: 0.1290\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0273 - mae: 0.1288 - val_loss: 0.0210 - val_mae: 0.1162\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0245 - mae: 0.1207 - val_loss: 0.0224 - val_mae: 0.1255\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0234 - mae: 0.1186 - val_loss: 0.0204 - val_mae: 0.1168\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0230 - mae: 0.1168 - val_loss: 0.0211 - val_mae: 0.1195\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 170us/step - loss: 0.0222 - mae: 0.1153 - val_loss: 0.0211 - val_mae: 0.1169\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 147us/step - loss: 0.0217 - mae: 0.1135 - val_loss: 0.0238 - val_mae: 0.1289\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 183us/step - loss: 0.0217 - mae: 0.1142 - val_loss: 0.0203 - val_mae: 0.1141\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 203us/step - loss: 0.0214 - mae: 0.1123 - val_loss: 0.0206 - val_mae: 0.1177\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0211 - mae: 0.1121 - val_loss: 0.0196 - val_mae: 0.1118\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0209 - mae: 0.1110 - val_loss: 0.0203 - val_mae: 0.1146\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 106us/step - loss: 0.0207 - mae: 0.1107 - val_loss: 0.0200 - val_mae: 0.1116\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0207 - mae: 0.1104 - val_loss: 0.0210 - val_mae: 0.1186\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0205 - mae: 0.1099 - val_loss: 0.0202 - val_mae: 0.1139\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0205 - mae: 0.1107 - val_loss: 0.0200 - val_mae: 0.1140\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0202 - mae: 0.1098 - val_loss: 0.0196 - val_mae: 0.1121\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0200 - mae: 0.1088 - val_loss: 0.0228 - val_mae: 0.1241\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0199 - mae: 0.1091 - val_loss: 0.0211 - val_mae: 0.1182\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0200 - mae: 0.1092 - val_loss: 0.0195 - val_mae: 0.1119\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0196 - mae: 0.1073 - val_loss: 0.0193 - val_mae: 0.1107\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0195 - mae: 0.1071 - val_loss: 0.0192 - val_mae: 0.1106\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0194 - mae: 0.1063 - val_loss: 0.0197 - val_mae: 0.1137\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0194 - mae: 0.1064 - val_loss: 0.0193 - val_mae: 0.1107\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0192 - mae: 0.1057 - val_loss: 0.0202 - val_mae: 0.1146\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0191 - mae: 0.1062 - val_loss: 0.0192 - val_mae: 0.1101\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0192 - mae: 0.1066 - val_loss: 0.0194 - val_mae: 0.1112\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0188 - mae: 0.1058 - val_loss: 0.0208 - val_mae: 0.1168\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 106us/step - loss: 0.0187 - mae: 0.1058 - val_loss: 0.0195 - val_mae: 0.1098\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0188 - mae: 0.1055 - val_loss: 0.0202 - val_mae: 0.1112\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0189 - mae: 0.1053 - val_loss: 0.0198 - val_mae: 0.1132\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 148us/step - loss: 0.0184 - mae: 0.1041 - val_loss: 0.0196 - val_mae: 0.1119\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.1049 - val_loss: 0.0211 - val_mae: 0.1186\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0185 - mae: 0.1049 - val_loss: 0.0198 - val_mae: 0.1135\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0186 - mae: 0.1043 - val_loss: 0.0183 - val_mae: 0.1067\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.1034 - val_loss: 0.0213 - val_mae: 0.1189\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0184 - mae: 0.1029 - val_loss: 0.0191 - val_mae: 0.1107\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 169us/step - loss: 0.0179 - mae: 0.1034 - val_loss: 0.0189 - val_mae: 0.1072\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 183us/step - loss: 0.0183 - mae: 0.1032 - val_loss: 0.0181 - val_mae: 0.1056\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0180 - mae: 0.1024 - val_loss: 0.0187 - val_mae: 0.1090\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0180 - mae: 0.1023 - val_loss: 0.0192 - val_mae: 0.1086\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0180 - mae: 0.1026 - val_loss: 0.0187 - val_mae: 0.1079\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 128us/step - loss: 0.0180 - mae: 0.1018 - val_loss: 0.0187 - val_mae: 0.1082\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0178 - mae: 0.1021 - val_loss: 0.0188 - val_mae: 0.1094\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0178 - mae: 0.1018 - val_loss: 0.0185 - val_mae: 0.1084\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0178 - mae: 0.1018 - val_loss: 0.0180 - val_mae: 0.1065\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.1017 - val_loss: 0.0181 - val_mae: 0.1068\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.1011 - val_loss: 0.0189 - val_mae: 0.1095\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.1013 - val_loss: 0.0187 - val_mae: 0.1070\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0177 - mae: 0.1009 - val_loss: 0.0178 - val_mae: 0.1052\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0177 - mae: 0.1000 - val_loss: 0.0194 - val_mae: 0.1123\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0174 - mae: 0.1012 - val_loss: 0.0195 - val_mae: 0.1089\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0175 - mae: 0.1008 - val_loss: 0.0183 - val_mae: 0.1066\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0176 - mae: 0.1004 - val_loss: 0.0180 - val_mae: 0.1055\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0175 - mae: 0.1001 - val_loss: 0.0178 - val_mae: 0.1046\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0175 - mae: 0.1003 - val_loss: 0.0175 - val_mae: 0.1032\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.1000 - val_loss: 0.0178 - val_mae: 0.1048\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0173 - mae: 0.0992 - val_loss: 0.0178 - val_mae: 0.1048\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0174 - mae: 0.0998 - val_loss: 0.0186 - val_mae: 0.1095\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0173 - mae: 0.0998 - val_loss: 0.0202 - val_mae: 0.1150\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0996 - val_loss: 0.0183 - val_mae: 0.1043\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0175 - mae: 0.0996 - val_loss: 0.0186 - val_mae: 0.1089\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0173 - mae: 0.0989 - val_loss: 0.0193 - val_mae: 0.1123\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0995 - val_loss: 0.0179 - val_mae: 0.1059\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0995 - val_loss: 0.0174 - val_mae: 0.1049\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0173 - mae: 0.0994 - val_loss: 0.0181 - val_mae: 0.1083\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0987 - val_loss: 0.0183 - val_mae: 0.1058\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0173 - mae: 0.0996 - val_loss: 0.0187 - val_mae: 0.1103\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0170 - mae: 0.0986 - val_loss: 0.0191 - val_mae: 0.1117\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0174 - mae: 0.0989 - val_loss: 0.0198 - val_mae: 0.1141\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0984 - val_loss: 0.0180 - val_mae: 0.1069\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0986 - val_loss: 0.0188 - val_mae: 0.1089\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0171 - mae: 0.0979 - val_loss: 0.0190 - val_mae: 0.1095\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0172 - mae: 0.0988 - val_loss: 0.0188 - val_mae: 0.1070\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0170 - mae: 0.0977 - val_loss: 0.0176 - val_mae: 0.1047\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0172 - mae: 0.0977 - val_loss: 0.0192 - val_mae: 0.1116\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0983 - val_loss: 0.0174 - val_mae: 0.1025\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0170 - mae: 0.0974 - val_loss: 0.0173 - val_mae: 0.1044\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0170 - mae: 0.0973 - val_loss: 0.0177 - val_mae: 0.1043\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0170 - mae: 0.0980 - val_loss: 0.0187 - val_mae: 0.1067\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0169 - mae: 0.0978 - val_loss: 0.0179 - val_mae: 0.1061\n"
     ]
    }
   ],
   "source": [
    "x_train_age = samples_with_age.drop([\"Age\", \"Survived\"], axis=1).values\n",
    "y_train_age = samples_with_age[\"Age\"].values\n",
    "\n",
    "number_of_epochs = 80\n",
    "number_of_folds = 5\n",
    "number_of_samples = len(x_train_age) // number_of_folds\n",
    "\n",
    "all_mae_histories = []\n",
    "all_val_mae_histories = []\n",
    "for i in range(number_of_folds):\n",
    "    print(\"processing fold #\", i)\n",
    "    partial_x_train_age = np.concatenate([x_train_age[:i*number_of_samples], x_train_age[(i+1)*number_of_samples:]])\n",
    "    parital_y_train_age = np.concatenate([y_train_age[:i*number_of_samples], y_train_age[(i+1)*number_of_samples:]])\n",
    "    \n",
    "    partial_x_validation_age = x_train_age[i*number_of_samples:(i+1)*number_of_samples]\n",
    "    partial_y_validation_age = y_train_age[i*number_of_samples:(i+1)*number_of_samples]\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(x_train_age.shape[1], activation=\"relu\", input_shape=(x_train_age.shape[1],)))\n",
    "    model.add(layers.Dense(12, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"mse\",\n",
    "                  metrics=[\"mae\"])\n",
    "\n",
    "    history = model.fit(partial_x_train_age,\n",
    "                        parital_y_train_age,\n",
    "                        epochs=number_of_epochs,\n",
    "                        batch_size=16,\n",
    "                        validation_data=(partial_x_validation_age, partial_y_validation_age))\n",
    "    all_mae_histories.append(history.history['mae'])\n",
    "    all_val_mae_histories.append(history.history['val_mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(number_of_epochs)]\n",
    "average_val_mae_history = [np.mean([x[i] for x in all_val_mae_histories]) for i in range(number_of_epochs)]\n",
    "\n",
    "epochs = range(1, number_of_epochs + 1)\n",
    "\n",
    "plt.plot(epochs, average_mae_history, \"b\", label=\"Training MAE\")\n",
    "plt.plot(epochs, average_val_mae_history, \"b\", label=\"Validation MAE\", c=\"red\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results for age prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.457355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.409413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.326684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034439</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "6                 0.0     1.0  0.457355    0.0  0.000000  0.016510     0.0   \n",
       "18                1.0     0.5  0.409413    0.0  0.000000  0.025374     0.0   \n",
       "20                1.0     1.0  0.344681    0.0  0.000000  0.014102     1.0   \n",
       "27                0.0     1.0  0.326684    0.0  0.000000  0.014102     0.0   \n",
       "29                1.0     1.0  0.274098    0.0  0.000000  0.015379     1.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1300              NaN     1.0  0.274099    0.0  0.000000  0.015070     1.0   \n",
       "1302              NaN     1.0  0.274099    0.0  0.000000  0.015127     1.0   \n",
       "1305              NaN     1.0  0.344905    0.0  0.000000  0.015713     0.0   \n",
       "1308              NaN     1.0  0.344905    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0  0.034439    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  STON/O  W./C.  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "6             1.0  0.0  1.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "18            1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "20            0.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "27            1.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "29            0.0  0.0  1.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...     ...    ...  ...  ...   \n",
       "1300          0.0  0.0  1.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1302          0.0  0.0  1.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "6                 0.0   0.0  0.0   0.0  \n",
       "18                0.0   0.0  0.0   0.0  \n",
       "20                0.0   0.0  0.0   0.0  \n",
       "27                0.0   0.0  0.0   0.0  \n",
       "29                0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1300              0.0   0.0  0.0   0.0  \n",
       "1302              0.0   0.0  0.0   0.0  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[263 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_age = model.predict(samples_without_age.drop([\"Survived\", \"Age\"], axis=1))\n",
    "samples_without_age.loc[:,\"Age\"] = results_age\n",
    "samples_without_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034439</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1300              NaN     1.0  0.274099    0.0  0.000000  0.015070     1.0   \n",
       "1302              NaN     1.0  0.274099    0.0  0.000000  0.015127     1.0   \n",
       "1305              NaN     1.0  0.344905    0.0  0.000000  0.015713     0.0   \n",
       "1308              NaN     1.0  0.344905    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0  0.034439    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  STON/O  W./C.  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0     1.0    0.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...     ...    ...  ...  ...   \n",
       "1300          0.0  0.0  1.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1302          0.0  0.0  1.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1300              0.0   0.0  0.0   0.0  \n",
       "1302              0.0   0.0  0.0   0.0  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[1309 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data_with_predicted_age = pd.concat([samples_with_age, samples_without_age])\n",
    "normalized_data_with_predicted_age.to_csv(\"../Output/normalized_data_with_predicted_age.csv\", index=True)\n",
    "normalized_data_with_predicted_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare original and predicted Age histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "scalar = 80\n",
    "\n",
    "plt.hist(samples_with_age.Age*scalar, range(scalar))\n",
    "plt.title(\"Original Age\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(results_age*scalar, range(scalar))\n",
    "plt.title(\"Predicted Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
