{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1300              NaN     1.0  0.260001    0.0  0.000000  0.015070     1.0   \n",
       "1302              NaN     1.0  0.259994    0.0  0.000000  0.015127     1.0   \n",
       "1305              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1308              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0  0.017290    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0    0.0     1.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "1300          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1302          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1300              0.0   0.0  0.0   0.0  \n",
       "1302              0.0   0.0  0.0   0.0  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[1309 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "normalized_data = pd.read_csv(\"normalized_data_with_predicted_age.csv\", index_col=0)\n",
    "normalized_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.267828</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.135753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274228</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "860               0.0     1.0  0.331168    0.0  0.000000  0.014110     0.0   \n",
       "864               0.0     1.0  0.267828    1.6  0.333333  0.135753     1.0   \n",
       "869               0.0     1.0  0.360791    0.0  0.000000  0.018543     0.0   \n",
       "879               0.0     1.0  0.360609    0.0  0.000000  0.015412     0.0   \n",
       "889               0.0     1.0  0.274228    0.2  0.333333  0.045771     1.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0    0.0     1.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "860           1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "864           0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  1.0  0.0   \n",
       "869           1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "879           1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "889           0.0  0.0  0.0  ...         0.0  0.0    1.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "860               0.0   0.0  0.0   0.0  \n",
       "864               0.0   1.0  1.0   0.0  \n",
       "869               0.0   0.0  0.0   0.0  \n",
       "879               0.0   0.0  0.0   0.0  \n",
       "889               0.0   0.0  0.0   0.0  \n",
       "\n",
       "[891 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_data = normalized_data[normalized_data.Survived.notna()]\n",
    "normalized_test_data = normalized_data[normalized_data.Survived.isna()]\n",
    "normalized_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/100\n",
      "713/713 [==============================] - 0s 396us/step - loss: 0.5786 - acc: 0.6971 - val_loss: 0.5051 - val_acc: 0.7865\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 0s 156us/step - loss: 0.5133 - acc: 0.7854 - val_loss: 0.4898 - val_acc: 0.7865\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4983 - acc: 0.7896 - val_loss: 0.4810 - val_acc: 0.7809\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4676 - acc: 0.8022 - val_loss: 0.4855 - val_acc: 0.7865\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.4628 - acc: 0.7924 - val_loss: 0.4912 - val_acc: 0.7978\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4492 - acc: 0.8008 - val_loss: 0.4688 - val_acc: 0.7978\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4448 - acc: 0.8065 - val_loss: 0.4704 - val_acc: 0.7978\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.4207 - acc: 0.7994 - val_loss: 0.4665 - val_acc: 0.7921\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 0s 178us/step - loss: 0.4203 - acc: 0.8107 - val_loss: 0.4714 - val_acc: 0.8034\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.4181 - acc: 0.8289 - val_loss: 0.4686 - val_acc: 0.8090\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.4200 - acc: 0.8205 - val_loss: 0.4629 - val_acc: 0.8090\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.4115 - acc: 0.8345 - val_loss: 0.4728 - val_acc: 0.8146\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4075 - acc: 0.8401 - val_loss: 0.4707 - val_acc: 0.7978\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 0s 175us/step - loss: 0.3880 - acc: 0.8443 - val_loss: 0.4660 - val_acc: 0.7978\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 0s 158us/step - loss: 0.4025 - acc: 0.8387 - val_loss: 0.4730 - val_acc: 0.7921\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3998 - acc: 0.8373 - val_loss: 0.4625 - val_acc: 0.8034\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3934 - acc: 0.8359 - val_loss: 0.4597 - val_acc: 0.8034\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3979 - acc: 0.8401 - val_loss: 0.4676 - val_acc: 0.7978\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3731 - acc: 0.8513 - val_loss: 0.4863 - val_acc: 0.8371\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 0s 158us/step - loss: 0.3790 - acc: 0.8443 - val_loss: 0.4812 - val_acc: 0.8090\n",
      "Epoch 21/100\n",
      "713/713 [==============================] - 0s 151us/step - loss: 0.3818 - acc: 0.8513 - val_loss: 0.4684 - val_acc: 0.8034\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3811 - acc: 0.8485 - val_loss: 0.4779 - val_acc: 0.7921\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 0s 152us/step - loss: 0.3767 - acc: 0.8527 - val_loss: 0.4753 - val_acc: 0.7978\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3910 - acc: 0.8513 - val_loss: 0.4792 - val_acc: 0.7809\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3808 - acc: 0.8457 - val_loss: 0.4734 - val_acc: 0.7978\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3852 - acc: 0.8555 - val_loss: 0.4949 - val_acc: 0.8034\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 0s 150us/step - loss: 0.3883 - acc: 0.8443 - val_loss: 0.4843 - val_acc: 0.7865\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3801 - acc: 0.8541 - val_loss: 0.4824 - val_acc: 0.7921\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 0s 150us/step - loss: 0.3714 - acc: 0.8513 - val_loss: 0.4882 - val_acc: 0.7921\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3764 - acc: 0.8527 - val_loss: 0.4788 - val_acc: 0.7978\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3727 - acc: 0.8513 - val_loss: 0.4787 - val_acc: 0.8034\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3634 - acc: 0.8513 - val_loss: 0.4798 - val_acc: 0.7978\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3792 - acc: 0.8443 - val_loss: 0.4798 - val_acc: 0.7978\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3671 - acc: 0.8612 - val_loss: 0.5106 - val_acc: 0.8034\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3711 - acc: 0.8527 - val_loss: 0.4808 - val_acc: 0.8034\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3657 - acc: 0.8555 - val_loss: 0.4852 - val_acc: 0.8034\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3654 - acc: 0.8527 - val_loss: 0.4878 - val_acc: 0.7978\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3661 - acc: 0.8569 - val_loss: 0.4917 - val_acc: 0.7809\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3617 - acc: 0.8527 - val_loss: 0.5028 - val_acc: 0.7640\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3726 - acc: 0.8499 - val_loss: 0.5001 - val_acc: 0.7697\n",
      "Epoch 41/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3663 - acc: 0.8485 - val_loss: 0.5029 - val_acc: 0.7753\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3649 - acc: 0.8555 - val_loss: 0.4922 - val_acc: 0.8034\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 0s 197us/step - loss: 0.3630 - acc: 0.8583 - val_loss: 0.5014 - val_acc: 0.7978\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 0s 153us/step - loss: 0.3593 - acc: 0.8569 - val_loss: 0.5113 - val_acc: 0.7865\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3564 - acc: 0.8513 - val_loss: 0.5109 - val_acc: 0.7921\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3679 - acc: 0.8527 - val_loss: 0.5014 - val_acc: 0.8034\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3676 - acc: 0.8583 - val_loss: 0.5051 - val_acc: 0.8034\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3562 - acc: 0.8569 - val_loss: 0.5003 - val_acc: 0.8034\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3555 - acc: 0.8640 - val_loss: 0.5051 - val_acc: 0.7921\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3635 - acc: 0.8583 - val_loss: 0.5179 - val_acc: 0.8202\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3570 - acc: 0.8626 - val_loss: 0.5152 - val_acc: 0.8034\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3576 - acc: 0.8569 - val_loss: 0.5336 - val_acc: 0.7865\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3643 - acc: 0.8583 - val_loss: 0.5075 - val_acc: 0.7978\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3507 - acc: 0.8626 - val_loss: 0.5274 - val_acc: 0.8034\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3494 - acc: 0.8626 - val_loss: 0.5350 - val_acc: 0.8090\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3565 - acc: 0.8583 - val_loss: 0.5226 - val_acc: 0.7865\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3544 - acc: 0.8569 - val_loss: 0.5121 - val_acc: 0.7921\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3549 - acc: 0.8597 - val_loss: 0.5222 - val_acc: 0.8034\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3517 - acc: 0.8612 - val_loss: 0.5391 - val_acc: 0.7640\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 0s 148us/step - loss: 0.3482 - acc: 0.8682 - val_loss: 0.5292 - val_acc: 0.8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3538 - acc: 0.8541 - val_loss: 0.5244 - val_acc: 0.8146\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3491 - acc: 0.8597 - val_loss: 0.5353 - val_acc: 0.7978\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3378 - acc: 0.8682 - val_loss: 0.5403 - val_acc: 0.8034\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3509 - acc: 0.8682 - val_loss: 0.5380 - val_acc: 0.7865\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3416 - acc: 0.8626 - val_loss: 0.5371 - val_acc: 0.8034\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3437 - acc: 0.8654 - val_loss: 0.5352 - val_acc: 0.7865\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3532 - acc: 0.8640 - val_loss: 0.5377 - val_acc: 0.8034\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3560 - acc: 0.8668 - val_loss: 0.5365 - val_acc: 0.8090\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3384 - acc: 0.8640 - val_loss: 0.5504 - val_acc: 0.7809\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3496 - acc: 0.8682 - val_loss: 0.5393 - val_acc: 0.7978\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3551 - acc: 0.8654 - val_loss: 0.5505 - val_acc: 0.8090\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3460 - acc: 0.8612 - val_loss: 0.5388 - val_acc: 0.8090\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3461 - acc: 0.8654 - val_loss: 0.5493 - val_acc: 0.8090\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3500 - acc: 0.8640 - val_loss: 0.5580 - val_acc: 0.7865\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3421 - acc: 0.8696 - val_loss: 0.5621 - val_acc: 0.8146\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3499 - acc: 0.8583 - val_loss: 0.5543 - val_acc: 0.7809\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3471 - acc: 0.8597 - val_loss: 0.5643 - val_acc: 0.7865\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3607 - acc: 0.8541 - val_loss: 0.5562 - val_acc: 0.8034\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3451 - acc: 0.8626 - val_loss: 0.5611 - val_acc: 0.8034\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3512 - acc: 0.8555 - val_loss: 0.5637 - val_acc: 0.7697\n",
      "Epoch 81/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3551 - acc: 0.8682 - val_loss: 0.5587 - val_acc: 0.7921\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3469 - acc: 0.8626 - val_loss: 0.5617 - val_acc: 0.7865\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3429 - acc: 0.8640 - val_loss: 0.5811 - val_acc: 0.7584\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3360 - acc: 0.8682 - val_loss: 0.5646 - val_acc: 0.7921\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3513 - acc: 0.8612 - val_loss: 0.5715 - val_acc: 0.7865\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3370 - acc: 0.8724 - val_loss: 0.5700 - val_acc: 0.7921\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3418 - acc: 0.8682 - val_loss: 0.5690 - val_acc: 0.7865\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3389 - acc: 0.8612 - val_loss: 0.5781 - val_acc: 0.7921\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3383 - acc: 0.8724 - val_loss: 0.5694 - val_acc: 0.7921\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3442 - acc: 0.8696 - val_loss: 0.5715 - val_acc: 0.7978\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3398 - acc: 0.8668 - val_loss: 0.5663 - val_acc: 0.8258\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3359 - acc: 0.8710 - val_loss: 0.5897 - val_acc: 0.7978\n",
      "Epoch 93/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3339 - acc: 0.8668 - val_loss: 0.5773 - val_acc: 0.7865\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3494 - acc: 0.8654 - val_loss: 0.5774 - val_acc: 0.7921\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3356 - acc: 0.8640 - val_loss: 0.5810 - val_acc: 0.7921\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3390 - acc: 0.8752 - val_loss: 0.5940 - val_acc: 0.8090\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3452 - acc: 0.8696 - val_loss: 0.5720 - val_acc: 0.7978\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3434 - acc: 0.8626 - val_loss: 0.5697 - val_acc: 0.7921\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 0s 163us/step - loss: 0.3448 - acc: 0.8654 - val_loss: 0.5903 - val_acc: 0.7865\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 0s 218us/step - loss: 0.3399 - acc: 0.8583 - val_loss: 0.5863 - val_acc: 0.7921\n",
      "processing fold # 1\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/100\n",
      "713/713 [==============================] - 0s 382us/step - loss: 0.6033 - acc: 0.7125 - val_loss: 0.5238 - val_acc: 0.7753\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4936 - acc: 0.7812 - val_loss: 0.4678 - val_acc: 0.7809\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4542 - acc: 0.7882 - val_loss: 0.4583 - val_acc: 0.8146\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4420 - acc: 0.8107 - val_loss: 0.4517 - val_acc: 0.7921\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4357 - acc: 0.7966 - val_loss: 0.4477 - val_acc: 0.7865\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4377 - acc: 0.8065 - val_loss: 0.4447 - val_acc: 0.8090\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4369 - acc: 0.8107 - val_loss: 0.4415 - val_acc: 0.7921\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4367 - acc: 0.8107 - val_loss: 0.4331 - val_acc: 0.8315\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.4262 - acc: 0.8135 - val_loss: 0.4305 - val_acc: 0.8258\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4137 - acc: 0.8135 - val_loss: 0.4329 - val_acc: 0.8258\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.4149 - acc: 0.8163 - val_loss: 0.4366 - val_acc: 0.8258\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4145 - acc: 0.8233 - val_loss: 0.4335 - val_acc: 0.8146\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.4008 - acc: 0.8233 - val_loss: 0.4397 - val_acc: 0.8090\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.4180 - acc: 0.8275 - val_loss: 0.4261 - val_acc: 0.8539\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3950 - acc: 0.8289 - val_loss: 0.4351 - val_acc: 0.8258\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4019 - acc: 0.8205 - val_loss: 0.4367 - val_acc: 0.8146\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3998 - acc: 0.8443 - val_loss: 0.4442 - val_acc: 0.8090\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 0s 155us/step - loss: 0.3976 - acc: 0.8387 - val_loss: 0.4341 - val_acc: 0.8371\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3924 - acc: 0.8443 - val_loss: 0.4393 - val_acc: 0.8258\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3858 - acc: 0.8513 - val_loss: 0.4563 - val_acc: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3715 - acc: 0.8415 - val_loss: 0.4471 - val_acc: 0.8539\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3907 - acc: 0.8513 - val_loss: 0.4489 - val_acc: 0.8371\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3806 - acc: 0.8429 - val_loss: 0.4499 - val_acc: 0.8371\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3812 - acc: 0.8527 - val_loss: 0.4541 - val_acc: 0.8202\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3917 - acc: 0.8457 - val_loss: 0.4578 - val_acc: 0.8202\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3788 - acc: 0.8471 - val_loss: 0.4606 - val_acc: 0.8202\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3793 - acc: 0.8513 - val_loss: 0.4605 - val_acc: 0.8315\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3775 - acc: 0.8499 - val_loss: 0.4565 - val_acc: 0.8427\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3728 - acc: 0.8597 - val_loss: 0.4556 - val_acc: 0.8427\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3733 - acc: 0.8443 - val_loss: 0.4688 - val_acc: 0.8315\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3862 - acc: 0.8401 - val_loss: 0.4639 - val_acc: 0.8315\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3745 - acc: 0.8485 - val_loss: 0.4736 - val_acc: 0.8258\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3653 - acc: 0.8471 - val_loss: 0.4715 - val_acc: 0.8371\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3760 - acc: 0.8485 - val_loss: 0.4681 - val_acc: 0.8258\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3753 - acc: 0.8429 - val_loss: 0.4693 - val_acc: 0.8371\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3668 - acc: 0.8527 - val_loss: 0.4765 - val_acc: 0.8483\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3648 - acc: 0.8471 - val_loss: 0.4935 - val_acc: 0.8146\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3636 - acc: 0.8527 - val_loss: 0.4822 - val_acc: 0.8427\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3711 - acc: 0.8499 - val_loss: 0.4859 - val_acc: 0.8258\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3777 - acc: 0.8429 - val_loss: 0.4806 - val_acc: 0.8371\n",
      "Epoch 41/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3648 - acc: 0.8555 - val_loss: 0.4877 - val_acc: 0.8483\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3511 - acc: 0.8626 - val_loss: 0.4880 - val_acc: 0.8427\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3620 - acc: 0.8527 - val_loss: 0.4943 - val_acc: 0.8315\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3652 - acc: 0.8541 - val_loss: 0.4972 - val_acc: 0.8539\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3530 - acc: 0.8555 - val_loss: 0.5017 - val_acc: 0.8258\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3629 - acc: 0.8415 - val_loss: 0.5020 - val_acc: 0.8539\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3583 - acc: 0.8555 - val_loss: 0.4924 - val_acc: 0.8427\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3681 - acc: 0.8429 - val_loss: 0.4859 - val_acc: 0.8539\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3633 - acc: 0.8471 - val_loss: 0.4955 - val_acc: 0.8371\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3575 - acc: 0.8555 - val_loss: 0.5021 - val_acc: 0.8315\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3491 - acc: 0.8626 - val_loss: 0.5139 - val_acc: 0.8258\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3610 - acc: 0.8555 - val_loss: 0.5043 - val_acc: 0.8539\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3642 - acc: 0.8541 - val_loss: 0.5133 - val_acc: 0.8483\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3535 - acc: 0.8527 - val_loss: 0.5078 - val_acc: 0.8539\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3607 - acc: 0.8457 - val_loss: 0.5177 - val_acc: 0.8258\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3665 - acc: 0.8555 - val_loss: 0.5095 - val_acc: 0.8483\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3602 - acc: 0.8654 - val_loss: 0.5129 - val_acc: 0.8427\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3575 - acc: 0.8513 - val_loss: 0.5213 - val_acc: 0.8483\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3437 - acc: 0.8499 - val_loss: 0.5247 - val_acc: 0.8202\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3566 - acc: 0.8569 - val_loss: 0.5194 - val_acc: 0.8483\n",
      "Epoch 61/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3491 - acc: 0.8583 - val_loss: 0.5204 - val_acc: 0.8371\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3462 - acc: 0.8597 - val_loss: 0.5306 - val_acc: 0.8315\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 0s 152us/step - loss: 0.3382 - acc: 0.8569 - val_loss: 0.5453 - val_acc: 0.8315\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3586 - acc: 0.8654 - val_loss: 0.5449 - val_acc: 0.8315\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3523 - acc: 0.8612 - val_loss: 0.5298 - val_acc: 0.8427\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3569 - acc: 0.8583 - val_loss: 0.5368 - val_acc: 0.8427\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3587 - acc: 0.8626 - val_loss: 0.5328 - val_acc: 0.8427\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3522 - acc: 0.8527 - val_loss: 0.5403 - val_acc: 0.8483\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3414 - acc: 0.8541 - val_loss: 0.5436 - val_acc: 0.8371\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3478 - acc: 0.8485 - val_loss: 0.5371 - val_acc: 0.8371\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3440 - acc: 0.8612 - val_loss: 0.5453 - val_acc: 0.8427\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3395 - acc: 0.8597 - val_loss: 0.5560 - val_acc: 0.8539\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 0s 160us/step - loss: 0.3473 - acc: 0.8640 - val_loss: 0.5443 - val_acc: 0.8539\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 0s 170us/step - loss: 0.3411 - acc: 0.8612 - val_loss: 0.5453 - val_acc: 0.8539\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3534 - acc: 0.8513 - val_loss: 0.5562 - val_acc: 0.8483\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3507 - acc: 0.8668 - val_loss: 0.5570 - val_acc: 0.8427\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3459 - acc: 0.8682 - val_loss: 0.5671 - val_acc: 0.8539\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3531 - acc: 0.8555 - val_loss: 0.5618 - val_acc: 0.8371\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3510 - acc: 0.8471 - val_loss: 0.5619 - val_acc: 0.8427\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 0s 203us/step - loss: 0.3465 - acc: 0.8612 - val_loss: 0.5779 - val_acc: 0.8483\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 0s 123us/step - loss: 0.3523 - acc: 0.8569 - val_loss: 0.5547 - val_acc: 0.8483\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3394 - acc: 0.8640 - val_loss: 0.5930 - val_acc: 0.8427\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3471 - acc: 0.8640 - val_loss: 0.5730 - val_acc: 0.8539\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3407 - acc: 0.8640 - val_loss: 0.5774 - val_acc: 0.8483\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3479 - acc: 0.8612 - val_loss: 0.5782 - val_acc: 0.8483\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3423 - acc: 0.8626 - val_loss: 0.5952 - val_acc: 0.8483\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3374 - acc: 0.8555 - val_loss: 0.5932 - val_acc: 0.8371\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3407 - acc: 0.8668 - val_loss: 0.5863 - val_acc: 0.8371\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3536 - acc: 0.8541 - val_loss: 0.5752 - val_acc: 0.8483\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3321 - acc: 0.8597 - val_loss: 0.5785 - val_acc: 0.8371\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3436 - acc: 0.8569 - val_loss: 0.5806 - val_acc: 0.8202\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3446 - acc: 0.8654 - val_loss: 0.5813 - val_acc: 0.8371\n",
      "Epoch 93/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3420 - acc: 0.8583 - val_loss: 0.5984 - val_acc: 0.8427\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3372 - acc: 0.8527 - val_loss: 0.5896 - val_acc: 0.8427\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3470 - acc: 0.8612 - val_loss: 0.5863 - val_acc: 0.8483\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3458 - acc: 0.8583 - val_loss: 0.5881 - val_acc: 0.8427\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 0s 152us/step - loss: 0.3415 - acc: 0.8682 - val_loss: 0.6069 - val_acc: 0.8427\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3431 - acc: 0.8597 - val_loss: 0.5976 - val_acc: 0.8427\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3402 - acc: 0.8626 - val_loss: 0.6147 - val_acc: 0.8202\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3296 - acc: 0.8752 - val_loss: 0.6398 - val_acc: 0.8090\n",
      "processing fold # 2\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/100\n",
      "713/713 [==============================] - 0s 401us/step - loss: 0.5696 - acc: 0.7391 - val_loss: 0.5769 - val_acc: 0.7191\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4855 - acc: 0.8008 - val_loss: 0.5401 - val_acc: 0.7360\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4564 - acc: 0.8135 - val_loss: 0.5358 - val_acc: 0.7416\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4539 - acc: 0.8177 - val_loss: 0.5286 - val_acc: 0.7584\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4423 - acc: 0.8093 - val_loss: 0.5134 - val_acc: 0.7528\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.4427 - acc: 0.8135 - val_loss: 0.5255 - val_acc: 0.7640\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4343 - acc: 0.8149 - val_loss: 0.5112 - val_acc: 0.7528\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.4321 - acc: 0.8149 - val_loss: 0.5067 - val_acc: 0.7640\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4050 - acc: 0.8415 - val_loss: 0.5125 - val_acc: 0.7640\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4068 - acc: 0.8261 - val_loss: 0.5189 - val_acc: 0.7584\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.4066 - acc: 0.8261 - val_loss: 0.5035 - val_acc: 0.7640\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3971 - acc: 0.8303 - val_loss: 0.5165 - val_acc: 0.7360\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3915 - acc: 0.8331 - val_loss: 0.5063 - val_acc: 0.7416\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3995 - acc: 0.8317 - val_loss: 0.5101 - val_acc: 0.7640\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3917 - acc: 0.8373 - val_loss: 0.5153 - val_acc: 0.7472\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3997 - acc: 0.8331 - val_loss: 0.5076 - val_acc: 0.7584\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4023 - acc: 0.8331 - val_loss: 0.5203 - val_acc: 0.7472\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3835 - acc: 0.8429 - val_loss: 0.5125 - val_acc: 0.7697\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3846 - acc: 0.8555 - val_loss: 0.5194 - val_acc: 0.7697\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3832 - acc: 0.8499 - val_loss: 0.5274 - val_acc: 0.7528\n",
      "Epoch 21/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3918 - acc: 0.8443 - val_loss: 0.5095 - val_acc: 0.7640\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3877 - acc: 0.8499 - val_loss: 0.5226 - val_acc: 0.7584\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3850 - acc: 0.8569 - val_loss: 0.5230 - val_acc: 0.7753\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3818 - acc: 0.8527 - val_loss: 0.5190 - val_acc: 0.7584\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3715 - acc: 0.8457 - val_loss: 0.5216 - val_acc: 0.7753\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3837 - acc: 0.8499 - val_loss: 0.5568 - val_acc: 0.7640\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3797 - acc: 0.8471 - val_loss: 0.5610 - val_acc: 0.7528\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3749 - acc: 0.8471 - val_loss: 0.5366 - val_acc: 0.7584\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3728 - acc: 0.8513 - val_loss: 0.5488 - val_acc: 0.7472\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3732 - acc: 0.8527 - val_loss: 0.5456 - val_acc: 0.7753\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3719 - acc: 0.8513 - val_loss: 0.5504 - val_acc: 0.7640\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3711 - acc: 0.8457 - val_loss: 0.5524 - val_acc: 0.7640\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 0s 154us/step - loss: 0.3702 - acc: 0.8555 - val_loss: 0.5588 - val_acc: 0.7584\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 0s 180us/step - loss: 0.3620 - acc: 0.8513 - val_loss: 0.5762 - val_acc: 0.7528\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3641 - acc: 0.8527 - val_loss: 0.5550 - val_acc: 0.7584\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3571 - acc: 0.8583 - val_loss: 0.5748 - val_acc: 0.7584\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3666 - acc: 0.8541 - val_loss: 0.5918 - val_acc: 0.7528\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3664 - acc: 0.8555 - val_loss: 0.5647 - val_acc: 0.7640\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3670 - acc: 0.8485 - val_loss: 0.5757 - val_acc: 0.7584\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3546 - acc: 0.8597 - val_loss: 0.5646 - val_acc: 0.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3718 - acc: 0.8583 - val_loss: 0.6038 - val_acc: 0.7640\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3612 - acc: 0.8555 - val_loss: 0.5792 - val_acc: 0.7528\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3566 - acc: 0.8626 - val_loss: 0.5898 - val_acc: 0.7528\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3612 - acc: 0.8597 - val_loss: 0.5868 - val_acc: 0.7697\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3595 - acc: 0.8597 - val_loss: 0.6022 - val_acc: 0.7584\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3551 - acc: 0.8583 - val_loss: 0.6031 - val_acc: 0.7528\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3561 - acc: 0.8597 - val_loss: 0.6019 - val_acc: 0.7528\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3648 - acc: 0.8626 - val_loss: 0.6059 - val_acc: 0.7584\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3589 - acc: 0.8527 - val_loss: 0.6166 - val_acc: 0.7528\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3639 - acc: 0.8555 - val_loss: 0.6403 - val_acc: 0.7584\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3481 - acc: 0.8710 - val_loss: 0.6308 - val_acc: 0.7528\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3532 - acc: 0.8569 - val_loss: 0.6340 - val_acc: 0.7640\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3606 - acc: 0.8555 - val_loss: 0.6193 - val_acc: 0.7528\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 0s 178us/step - loss: 0.3558 - acc: 0.8569 - val_loss: 0.6118 - val_acc: 0.7528\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3564 - acc: 0.8612 - val_loss: 0.6492 - val_acc: 0.7528\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3476 - acc: 0.8682 - val_loss: 0.6454 - val_acc: 0.7584\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 0s 192us/step - loss: 0.3468 - acc: 0.8640 - val_loss: 0.6526 - val_acc: 0.7584\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3610 - acc: 0.8612 - val_loss: 0.6541 - val_acc: 0.7528\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3534 - acc: 0.8555 - val_loss: 0.6431 - val_acc: 0.7584\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3396 - acc: 0.8640 - val_loss: 0.6810 - val_acc: 0.7528\n",
      "Epoch 61/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3445 - acc: 0.8612 - val_loss: 0.6638 - val_acc: 0.7528\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3540 - acc: 0.8597 - val_loss: 0.6843 - val_acc: 0.7472\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3541 - acc: 0.8640 - val_loss: 0.6652 - val_acc: 0.7528\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3516 - acc: 0.8668 - val_loss: 0.6653 - val_acc: 0.7472\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3498 - acc: 0.8583 - val_loss: 0.6561 - val_acc: 0.7472\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3522 - acc: 0.8569 - val_loss: 0.6774 - val_acc: 0.7697\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3607 - acc: 0.8597 - val_loss: 0.6707 - val_acc: 0.7472\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3370 - acc: 0.8724 - val_loss: 0.6914 - val_acc: 0.7472\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3397 - acc: 0.8626 - val_loss: 0.6881 - val_acc: 0.7472\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3453 - acc: 0.8640 - val_loss: 0.7073 - val_acc: 0.7472\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3480 - acc: 0.8612 - val_loss: 0.6894 - val_acc: 0.7472\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3447 - acc: 0.8682 - val_loss: 0.7040 - val_acc: 0.7528\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3446 - acc: 0.8654 - val_loss: 0.6988 - val_acc: 0.7472\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3471 - acc: 0.8640 - val_loss: 0.6972 - val_acc: 0.7472\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3455 - acc: 0.8569 - val_loss: 0.7355 - val_acc: 0.7472\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3503 - acc: 0.8569 - val_loss: 0.7352 - val_acc: 0.7528\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3439 - acc: 0.8640 - val_loss: 0.7405 - val_acc: 0.7472\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3471 - acc: 0.8640 - val_loss: 0.6822 - val_acc: 0.7528\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3388 - acc: 0.8682 - val_loss: 0.7510 - val_acc: 0.7472\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3389 - acc: 0.8612 - val_loss: 0.7518 - val_acc: 0.7416\n",
      "Epoch 81/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3561 - acc: 0.8640 - val_loss: 0.7295 - val_acc: 0.7472\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3516 - acc: 0.8654 - val_loss: 0.7275 - val_acc: 0.7472\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3422 - acc: 0.8612 - val_loss: 0.7707 - val_acc: 0.7472\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3424 - acc: 0.8640 - val_loss: 0.7717 - val_acc: 0.7472\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3464 - acc: 0.8654 - val_loss: 0.7928 - val_acc: 0.7472\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3489 - acc: 0.8612 - val_loss: 0.7734 - val_acc: 0.7472\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3390 - acc: 0.8654 - val_loss: 0.7814 - val_acc: 0.7472\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3356 - acc: 0.8668 - val_loss: 0.7817 - val_acc: 0.7528\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 0s 145us/step - loss: 0.3442 - acc: 0.8626 - val_loss: 0.7706 - val_acc: 0.7472\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3418 - acc: 0.8710 - val_loss: 0.7781 - val_acc: 0.7416\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3387 - acc: 0.8668 - val_loss: 0.7932 - val_acc: 0.7416\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3495 - acc: 0.8668 - val_loss: 0.7742 - val_acc: 0.7472\n",
      "Epoch 93/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3322 - acc: 0.8682 - val_loss: 0.7508 - val_acc: 0.7472\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3382 - acc: 0.8696 - val_loss: 0.7890 - val_acc: 0.7472\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3412 - acc: 0.8668 - val_loss: 0.7790 - val_acc: 0.7416\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3347 - acc: 0.8654 - val_loss: 0.7648 - val_acc: 0.7584\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3510 - acc: 0.8654 - val_loss: 0.7978 - val_acc: 0.7416\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3438 - acc: 0.8654 - val_loss: 0.7777 - val_acc: 0.7416\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3450 - acc: 0.8668 - val_loss: 0.7945 - val_acc: 0.7416\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3466 - acc: 0.8738 - val_loss: 0.8147 - val_acc: 0.7416\n",
      "processing fold # 3\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 0s 394us/step - loss: 0.5945 - acc: 0.6844 - val_loss: 0.4892 - val_acc: 0.8146\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.5186 - acc: 0.7812 - val_loss: 0.4529 - val_acc: 0.7978\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4856 - acc: 0.7966 - val_loss: 0.4354 - val_acc: 0.8034\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4820 - acc: 0.7924 - val_loss: 0.4273 - val_acc: 0.8034\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.4589 - acc: 0.8065 - val_loss: 0.4248 - val_acc: 0.8034\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4487 - acc: 0.8050 - val_loss: 0.4190 - val_acc: 0.8090\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.4632 - acc: 0.8107 - val_loss: 0.4131 - val_acc: 0.8034\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.4495 - acc: 0.8065 - val_loss: 0.4138 - val_acc: 0.8090\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4380 - acc: 0.8093 - val_loss: 0.4128 - val_acc: 0.8034\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4390 - acc: 0.8121 - val_loss: 0.4133 - val_acc: 0.8034\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4339 - acc: 0.8149 - val_loss: 0.4112 - val_acc: 0.8090\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.4283 - acc: 0.8233 - val_loss: 0.4118 - val_acc: 0.8146\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4268 - acc: 0.8233 - val_loss: 0.4163 - val_acc: 0.8202\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.4184 - acc: 0.8303 - val_loss: 0.4084 - val_acc: 0.8090\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.4261 - acc: 0.8261 - val_loss: 0.4122 - val_acc: 0.8202\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4269 - acc: 0.8219 - val_loss: 0.4131 - val_acc: 0.8202\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.4251 - acc: 0.8303 - val_loss: 0.4099 - val_acc: 0.8090\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4148 - acc: 0.8317 - val_loss: 0.4181 - val_acc: 0.8146\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.4192 - acc: 0.8331 - val_loss: 0.4166 - val_acc: 0.8202\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4129 - acc: 0.8331 - val_loss: 0.4192 - val_acc: 0.8258\n",
      "Epoch 21/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.4149 - acc: 0.8247 - val_loss: 0.4116 - val_acc: 0.8202\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4087 - acc: 0.8289 - val_loss: 0.4116 - val_acc: 0.8315\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.4066 - acc: 0.8359 - val_loss: 0.4089 - val_acc: 0.8315\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4141 - acc: 0.8359 - val_loss: 0.4161 - val_acc: 0.8258\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 0s 150us/step - loss: 0.4088 - acc: 0.8373 - val_loss: 0.4081 - val_acc: 0.8315\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4101 - acc: 0.8415 - val_loss: 0.4100 - val_acc: 0.8202\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.4041 - acc: 0.8331 - val_loss: 0.4129 - val_acc: 0.8315\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.4076 - acc: 0.8401 - val_loss: 0.4198 - val_acc: 0.8258\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4148 - acc: 0.8443 - val_loss: 0.4131 - val_acc: 0.8315\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4059 - acc: 0.8429 - val_loss: 0.4232 - val_acc: 0.8202\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.4045 - acc: 0.8443 - val_loss: 0.4185 - val_acc: 0.8371\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.4047 - acc: 0.8471 - val_loss: 0.4200 - val_acc: 0.8258\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4058 - acc: 0.8345 - val_loss: 0.4073 - val_acc: 0.8258\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4164 - acc: 0.8331 - val_loss: 0.4072 - val_acc: 0.8202\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4051 - acc: 0.8387 - val_loss: 0.4067 - val_acc: 0.8258\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4058 - acc: 0.8401 - val_loss: 0.4226 - val_acc: 0.8202\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3936 - acc: 0.8387 - val_loss: 0.4100 - val_acc: 0.8483\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4080 - acc: 0.8359 - val_loss: 0.4144 - val_acc: 0.8258\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4079 - acc: 0.8415 - val_loss: 0.4258 - val_acc: 0.8315\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 0s 148us/step - loss: 0.3988 - acc: 0.8457 - val_loss: 0.4136 - val_acc: 0.8315\n",
      "Epoch 41/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3936 - acc: 0.8415 - val_loss: 0.4172 - val_acc: 0.8315\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3979 - acc: 0.8415 - val_loss: 0.4261 - val_acc: 0.8258\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3830 - acc: 0.8527 - val_loss: 0.4157 - val_acc: 0.8371\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3914 - acc: 0.8373 - val_loss: 0.4135 - val_acc: 0.8315\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3979 - acc: 0.8401 - val_loss: 0.4156 - val_acc: 0.8371\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3984 - acc: 0.8373 - val_loss: 0.4124 - val_acc: 0.8371\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3845 - acc: 0.8471 - val_loss: 0.4315 - val_acc: 0.8258\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3888 - acc: 0.8429 - val_loss: 0.4113 - val_acc: 0.8371\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3953 - acc: 0.8401 - val_loss: 0.4164 - val_acc: 0.8427\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3876 - acc: 0.8499 - val_loss: 0.4096 - val_acc: 0.8427\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3921 - acc: 0.8471 - val_loss: 0.4091 - val_acc: 0.8315\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3896 - acc: 0.8443 - val_loss: 0.4090 - val_acc: 0.8258\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3864 - acc: 0.8471 - val_loss: 0.4192 - val_acc: 0.8315\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3945 - acc: 0.8443 - val_loss: 0.4117 - val_acc: 0.8371\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3960 - acc: 0.8415 - val_loss: 0.4318 - val_acc: 0.8258\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 0s 158us/step - loss: 0.3847 - acc: 0.8513 - val_loss: 0.4229 - val_acc: 0.8202\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3769 - acc: 0.8471 - val_loss: 0.4158 - val_acc: 0.8427\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3792 - acc: 0.8513 - val_loss: 0.4227 - val_acc: 0.8315\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3783 - acc: 0.8457 - val_loss: 0.4210 - val_acc: 0.8371\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3879 - acc: 0.8555 - val_loss: 0.4254 - val_acc: 0.8371\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 0s 132us/step - loss: 0.3834 - acc: 0.8457 - val_loss: 0.4207 - val_acc: 0.8427\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3833 - acc: 0.8541 - val_loss: 0.4162 - val_acc: 0.8258\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3774 - acc: 0.8541 - val_loss: 0.4194 - val_acc: 0.8483\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3891 - acc: 0.8401 - val_loss: 0.4188 - val_acc: 0.8315\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3839 - acc: 0.8555 - val_loss: 0.4261 - val_acc: 0.8258\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3922 - acc: 0.8499 - val_loss: 0.4330 - val_acc: 0.8371\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3879 - acc: 0.8583 - val_loss: 0.4479 - val_acc: 0.8258\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3799 - acc: 0.8555 - val_loss: 0.4250 - val_acc: 0.8315\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 0s 152us/step - loss: 0.3815 - acc: 0.8457 - val_loss: 0.4266 - val_acc: 0.8483\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3725 - acc: 0.8541 - val_loss: 0.4330 - val_acc: 0.8202\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3847 - acc: 0.8513 - val_loss: 0.4278 - val_acc: 0.8371\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3706 - acc: 0.8541 - val_loss: 0.4266 - val_acc: 0.8483\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3766 - acc: 0.8499 - val_loss: 0.4302 - val_acc: 0.8371\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3789 - acc: 0.8541 - val_loss: 0.4341 - val_acc: 0.8202\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 0s 146us/step - loss: 0.3804 - acc: 0.8569 - val_loss: 0.4335 - val_acc: 0.8258\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.3843 - acc: 0.8457 - val_loss: 0.4458 - val_acc: 0.8371\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3813 - acc: 0.8513 - val_loss: 0.4555 - val_acc: 0.8258\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3846 - acc: 0.8471 - val_loss: 0.4479 - val_acc: 0.8202\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3769 - acc: 0.8485 - val_loss: 0.4376 - val_acc: 0.8427\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3696 - acc: 0.8569 - val_loss: 0.4316 - val_acc: 0.8483\n",
      "Epoch 81/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3768 - acc: 0.8471 - val_loss: 0.4379 - val_acc: 0.8315\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3759 - acc: 0.8626 - val_loss: 0.4375 - val_acc: 0.8258\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3725 - acc: 0.8583 - val_loss: 0.4387 - val_acc: 0.8146\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3716 - acc: 0.8555 - val_loss: 0.4481 - val_acc: 0.8427\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3779 - acc: 0.8499 - val_loss: 0.4816 - val_acc: 0.8146\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3745 - acc: 0.8555 - val_loss: 0.4411 - val_acc: 0.8090\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3711 - acc: 0.8555 - val_loss: 0.4607 - val_acc: 0.8315\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3641 - acc: 0.8612 - val_loss: 0.4380 - val_acc: 0.8090\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3773 - acc: 0.8569 - val_loss: 0.4359 - val_acc: 0.8427\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3750 - acc: 0.8527 - val_loss: 0.4421 - val_acc: 0.8258\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3741 - acc: 0.8583 - val_loss: 0.4381 - val_acc: 0.8315\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3717 - acc: 0.8527 - val_loss: 0.4601 - val_acc: 0.8202\n",
      "Epoch 93/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3652 - acc: 0.8513 - val_loss: 0.4542 - val_acc: 0.8258\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3792 - acc: 0.8527 - val_loss: 0.4458 - val_acc: 0.8315\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3732 - acc: 0.8555 - val_loss: 0.4623 - val_acc: 0.8258\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3687 - acc: 0.8513 - val_loss: 0.4467 - val_acc: 0.8315\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3678 - acc: 0.8640 - val_loss: 0.4664 - val_acc: 0.8315\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3762 - acc: 0.8471 - val_loss: 0.4586 - val_acc: 0.8315\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3722 - acc: 0.8555 - val_loss: 0.4703 - val_acc: 0.8258\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3734 - acc: 0.8513 - val_loss: 0.4672 - val_acc: 0.8146\n",
      "processing fold # 4\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/100\n",
      "713/713 [==============================] - 0s 380us/step - loss: 0.6545 - acc: 0.6550 - val_loss: 0.5993 - val_acc: 0.8146\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.5607 - acc: 0.7630 - val_loss: 0.4970 - val_acc: 0.8315\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.5082 - acc: 0.7896 - val_loss: 0.4652 - val_acc: 0.8315\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4990 - acc: 0.7798 - val_loss: 0.4491 - val_acc: 0.8315\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4776 - acc: 0.7854 - val_loss: 0.4373 - val_acc: 0.8483\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4566 - acc: 0.7854 - val_loss: 0.4320 - val_acc: 0.8258\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4708 - acc: 0.7812 - val_loss: 0.4285 - val_acc: 0.8371\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.4579 - acc: 0.7910 - val_loss: 0.4255 - val_acc: 0.8371\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4393 - acc: 0.8050 - val_loss: 0.4212 - val_acc: 0.8202\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4329 - acc: 0.8079 - val_loss: 0.4163 - val_acc: 0.8258\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.4491 - acc: 0.8093 - val_loss: 0.4121 - val_acc: 0.8371\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4385 - acc: 0.8036 - val_loss: 0.4046 - val_acc: 0.8371\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.4253 - acc: 0.8247 - val_loss: 0.4028 - val_acc: 0.8371\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.4173 - acc: 0.8149 - val_loss: 0.4096 - val_acc: 0.8090\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.4200 - acc: 0.8247 - val_loss: 0.4149 - val_acc: 0.7584\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4132 - acc: 0.8289 - val_loss: 0.4033 - val_acc: 0.8315\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 0s 151us/step - loss: 0.4006 - acc: 0.8345 - val_loss: 0.3964 - val_acc: 0.8371\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4047 - acc: 0.8205 - val_loss: 0.4054 - val_acc: 0.8202\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4118 - acc: 0.8289 - val_loss: 0.4031 - val_acc: 0.8258\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4025 - acc: 0.8359 - val_loss: 0.4119 - val_acc: 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4044 - acc: 0.8345 - val_loss: 0.3997 - val_acc: 0.8315\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3960 - acc: 0.8443 - val_loss: 0.4007 - val_acc: 0.8315\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3894 - acc: 0.8457 - val_loss: 0.4096 - val_acc: 0.8146\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3934 - acc: 0.8359 - val_loss: 0.3961 - val_acc: 0.8483\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3942 - acc: 0.8499 - val_loss: 0.4079 - val_acc: 0.8258\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3928 - acc: 0.8443 - val_loss: 0.4004 - val_acc: 0.8315\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3869 - acc: 0.8387 - val_loss: 0.3946 - val_acc: 0.8371\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3901 - acc: 0.8373 - val_loss: 0.3983 - val_acc: 0.8427\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3911 - acc: 0.8429 - val_loss: 0.4016 - val_acc: 0.8427\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3806 - acc: 0.8597 - val_loss: 0.4006 - val_acc: 0.8539\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3875 - acc: 0.8485 - val_loss: 0.4074 - val_acc: 0.8202\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3840 - acc: 0.8457 - val_loss: 0.4076 - val_acc: 0.8258\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3799 - acc: 0.8569 - val_loss: 0.4004 - val_acc: 0.8371\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3716 - acc: 0.8513 - val_loss: 0.4066 - val_acc: 0.8371\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3816 - acc: 0.8457 - val_loss: 0.4277 - val_acc: 0.7584\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3849 - acc: 0.8457 - val_loss: 0.4022 - val_acc: 0.8483\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3909 - acc: 0.8387 - val_loss: 0.4053 - val_acc: 0.8371\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 0s 147us/step - loss: 0.3864 - acc: 0.8513 - val_loss: 0.4120 - val_acc: 0.8258\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3782 - acc: 0.8457 - val_loss: 0.4000 - val_acc: 0.8596\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3804 - acc: 0.8457 - val_loss: 0.3996 - val_acc: 0.8539\n",
      "Epoch 41/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3736 - acc: 0.8541 - val_loss: 0.4197 - val_acc: 0.8258\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3753 - acc: 0.8555 - val_loss: 0.4029 - val_acc: 0.8596\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3722 - acc: 0.8597 - val_loss: 0.4051 - val_acc: 0.8427\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3725 - acc: 0.8555 - val_loss: 0.4010 - val_acc: 0.8427\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3732 - acc: 0.8513 - val_loss: 0.4020 - val_acc: 0.8427\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 0s 190us/step - loss: 0.3696 - acc: 0.8569 - val_loss: 0.4030 - val_acc: 0.8427\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3756 - acc: 0.8485 - val_loss: 0.4163 - val_acc: 0.8371\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3678 - acc: 0.8555 - val_loss: 0.4169 - val_acc: 0.8483\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3724 - acc: 0.8527 - val_loss: 0.4041 - val_acc: 0.8427\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3716 - acc: 0.8499 - val_loss: 0.4093 - val_acc: 0.8427\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3729 - acc: 0.8555 - val_loss: 0.4061 - val_acc: 0.8427\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3564 - acc: 0.8555 - val_loss: 0.4393 - val_acc: 0.7640\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3810 - acc: 0.8471 - val_loss: 0.4319 - val_acc: 0.7584\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3715 - acc: 0.8471 - val_loss: 0.4250 - val_acc: 0.8202\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3694 - acc: 0.8583 - val_loss: 0.4333 - val_acc: 0.7640\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3673 - acc: 0.8555 - val_loss: 0.4251 - val_acc: 0.8371\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3690 - acc: 0.8499 - val_loss: 0.4111 - val_acc: 0.8539\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3710 - acc: 0.8527 - val_loss: 0.4163 - val_acc: 0.8596\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3632 - acc: 0.8457 - val_loss: 0.4143 - val_acc: 0.8427\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.3631 - acc: 0.8555 - val_loss: 0.4133 - val_acc: 0.8427\n",
      "Epoch 61/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3730 - acc: 0.8541 - val_loss: 0.4362 - val_acc: 0.7697\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3659 - acc: 0.8583 - val_loss: 0.4256 - val_acc: 0.8427\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3676 - acc: 0.8569 - val_loss: 0.4214 - val_acc: 0.8427\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3588 - acc: 0.8513 - val_loss: 0.4129 - val_acc: 0.8427\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3580 - acc: 0.8555 - val_loss: 0.4203 - val_acc: 0.8483\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3602 - acc: 0.8612 - val_loss: 0.4269 - val_acc: 0.8483\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 0s 153us/step - loss: 0.3582 - acc: 0.8555 - val_loss: 0.4322 - val_acc: 0.7753\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3617 - acc: 0.8555 - val_loss: 0.4495 - val_acc: 0.7640\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3638 - acc: 0.8541 - val_loss: 0.4263 - val_acc: 0.8371\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3589 - acc: 0.8640 - val_loss: 0.4339 - val_acc: 0.7809\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 0s 149us/step - loss: 0.3662 - acc: 0.8541 - val_loss: 0.4227 - val_acc: 0.8427\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3553 - acc: 0.8668 - val_loss: 0.4191 - val_acc: 0.8483\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3565 - acc: 0.8654 - val_loss: 0.4267 - val_acc: 0.8427\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3582 - acc: 0.8541 - val_loss: 0.4298 - val_acc: 0.8427\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3610 - acc: 0.8541 - val_loss: 0.4238 - val_acc: 0.8427\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3583 - acc: 0.8527 - val_loss: 0.4277 - val_acc: 0.8483\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3560 - acc: 0.8612 - val_loss: 0.4233 - val_acc: 0.8427\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3508 - acc: 0.8569 - val_loss: 0.4375 - val_acc: 0.8427\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3476 - acc: 0.8569 - val_loss: 0.4343 - val_acc: 0.8427\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 0s 153us/step - loss: 0.3524 - acc: 0.8597 - val_loss: 0.4485 - val_acc: 0.8427\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 0s 122us/step - loss: 0.3553 - acc: 0.8569 - val_loss: 0.4417 - val_acc: 0.8315\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 0s 148us/step - loss: 0.3590 - acc: 0.8541 - val_loss: 0.4389 - val_acc: 0.8371\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3526 - acc: 0.8583 - val_loss: 0.4333 - val_acc: 0.8427\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3500 - acc: 0.8612 - val_loss: 0.4488 - val_acc: 0.8427\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 0s 144us/step - loss: 0.3528 - acc: 0.8668 - val_loss: 0.4545 - val_acc: 0.8371\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 0s 113us/step - loss: 0.3508 - acc: 0.8626 - val_loss: 0.4635 - val_acc: 0.7584\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3527 - acc: 0.8583 - val_loss: 0.4298 - val_acc: 0.8483\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3571 - acc: 0.8597 - val_loss: 0.4370 - val_acc: 0.8427\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3536 - acc: 0.8597 - val_loss: 0.4375 - val_acc: 0.8483\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3540 - acc: 0.8597 - val_loss: 0.4416 - val_acc: 0.8483\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3552 - acc: 0.8612 - val_loss: 0.4489 - val_acc: 0.8258\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3548 - acc: 0.8569 - val_loss: 0.4471 - val_acc: 0.8483\n",
      "Epoch 93/100\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3533 - acc: 0.8626 - val_loss: 0.4421 - val_acc: 0.8427\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 0s 150us/step - loss: 0.3485 - acc: 0.8626 - val_loss: 0.4589 - val_acc: 0.8427\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3508 - acc: 0.8583 - val_loss: 0.4591 - val_acc: 0.7697\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3406 - acc: 0.8555 - val_loss: 0.4670 - val_acc: 0.7697\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3427 - acc: 0.8583 - val_loss: 0.4491 - val_acc: 0.8596\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.3521 - acc: 0.8569 - val_loss: 0.4538 - val_acc: 0.8483\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3431 - acc: 0.8555 - val_loss: 0.4524 - val_acc: 0.8483\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.3488 - acc: 0.8555 - val_loss: 0.4653 - val_acc: 0.7809\n"
     ]
    }
   ],
   "source": [
    "x_train = normalized_train_data.drop([\"Survived\"], axis=1).values\n",
    "y_train = normalized_train_data[\"Survived\"].values\n",
    "\n",
    "number_of_epochs = 100\n",
    "number_of_folds = 5\n",
    "number_of_samples = len(x_train) // number_of_folds\n",
    "\n",
    "all_histories = []\n",
    "for i in range(number_of_folds):\n",
    "    print(\"processing fold #\", i)\n",
    "    \n",
    "    partial_x_train = np.concatenate([x_train[:i*number_of_samples],\n",
    "                                          x_train[(i+1)*number_of_samples:]])\n",
    "    parital_y_train = np.concatenate([y_train[:i*number_of_samples],\n",
    "                                          y_train[(i+1)*number_of_samples:]])\n",
    "    \n",
    "    partial_x_validation = x_train[i*number_of_samples:(i+1)*number_of_samples]\n",
    "    partial_y_validation = y_train[i*number_of_samples:(i+1)*number_of_samples]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(x_train.shape[1], activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"acc\"])\n",
    "\n",
    "    history = model.fit(partial_x_train,\n",
    "                        parital_y_train,\n",
    "                        epochs=number_of_epochs,\n",
    "                        batch_size=16,\n",
    "                        validation_data=[partial_x_validation,partial_y_validation])\n",
    "    all_histories.append(history.history)\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(x_train.shape[1], activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
    "# model.add(layers.Dense(64, activation=\"relu\"))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(32, activation=\"relu\"))\n",
    "# model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# model.compile(optimizer=\"rmsprop\",\n",
    "#               loss=\"binary_crossentropy\",\n",
    "#               metrics=[\"acc\"])\n",
    "\n",
    "# history = model.fit(x_train,\n",
    "#                     y_train,\n",
    "#                     epochs=number_of_epochs,\n",
    "#                     batch_size=16,\n",
    "#                     validation_data=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "loss_values = [np.mean([x[\"loss\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "val_loss_values = [np.mean([x[\"val_loss\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\", color=\"red\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc_values = [np.mean([x[\"acc\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "val_acc_values = [np.mean([x[\"val_acc\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "\n",
    "plt.plot(epochs, acc_values, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc_values, \"b\", label=\"Validation acc\", color=\"red\")\n",
    "plt.title(\"Training and validation acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 0\n",
       "894                 0\n",
       "895                 0\n",
       "896                 0\n",
       "...               ...\n",
       "1300                0\n",
       "1302                0\n",
       "1305                0\n",
       "1308                0\n",
       "1309                1\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(normalized_test_data.drop([\"Survived\"], axis=1))\n",
    "results = pd.DataFrame(results, columns=[\"Survived\"], index=normalized_test_data.index)\n",
    "\n",
    "results.loc[results.Survived < 0.5, [\"Survived\"]] = 0\n",
    "results.loc[results.Survived >= 0.5, [\"Survived\"]] = 1\n",
    "results = results.fillna(0)\n",
    "results.Survived = results.Survived.astype(int)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"Output/my_prediction.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with genderr submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example</th>\n",
       "      <th>MyPrediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1051</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1098</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1052</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Example  MyPrediction\n",
       "PassengerId                       \n",
       "896                1             0\n",
       "898                1             0\n",
       "910                1             0\n",
       "911                1             0\n",
       "955                1             0\n",
       "962                1             0\n",
       "971                1             0\n",
       "978                1             0\n",
       "982                1             0\n",
       "1009               1             0\n",
       "1010               1             0\n",
       "1051               0             1\n",
       "1057               1             0\n",
       "1098               1             0\n",
       "1155               1             0\n",
       "1173               0             1\n",
       "1176               1             0\n",
       "1183               1             0\n",
       "1201               1             0\n",
       "1205               1             0\n",
       "1237               1             0\n",
       "1251               1             0\n",
       "1254               1             0\n",
       "1275               1             0\n",
       "1296               0             1\n",
       "1301               0             1\n",
       "1003               1             0\n",
       "1019               1             0\n",
       "1052               1             0\n",
       "1092               1             0\n",
       "1108               1             0\n",
       "1119               1             0\n",
       "1174               1             0\n",
       "1182               0             1\n",
       "1196               1             0\n",
       "1300               1             0\n",
       "1302               1             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare = pd.read_csv(\"Dataset/gender_submission.csv\", index_col=0)\n",
    "compare = pd.read_csv(\"Output/799_64_05_32.csv\", index_col=0)\n",
    "compare = compare.rename(columns={\"Survived\": \"Example\"})\n",
    "compare = pd.concat([compare, results], axis=1)\n",
    "compare = compare.rename(columns={\"Survived\": \"MyPrediction\"})\n",
    "compare[compare.Example != compare.MyPrediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
