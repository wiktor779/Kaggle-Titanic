{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1300              NaN     1.0  0.260001    0.0  0.000000  0.015070     1.0   \n",
       "1302              NaN     1.0  0.259994    0.0  0.000000  0.015127     1.0   \n",
       "1305              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1308              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0  0.017290    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0    0.0     1.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "1300          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1302          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1300              0.0   0.0  0.0   0.0  \n",
       "1302              0.0   0.0  0.0   0.0  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[1309 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "normalized_data = pd.read_csv(\"normalized_data_with_predicted_age.csv\", index_col=0)\n",
    "normalized_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.267828</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.135753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274228</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "860               0.0     1.0  0.331168    0.0  0.000000  0.014110     0.0   \n",
       "864               0.0     1.0  0.267828    1.6  0.333333  0.135753     1.0   \n",
       "869               0.0     1.0  0.360791    0.0  0.000000  0.018543     0.0   \n",
       "879               0.0     1.0  0.360609    0.0  0.000000  0.015412     0.0   \n",
       "889               0.0     1.0  0.274228    0.2  0.333333  0.045771     1.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0    0.0     1.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "860           1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "864           0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  1.0  0.0   \n",
       "869           1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "879           1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "889           0.0  0.0  0.0  ...         0.0  0.0    1.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "860               0.0   0.0  0.0   0.0  \n",
       "864               0.0   1.0  1.0   0.0  \n",
       "869               0.0   0.0  0.0   0.0  \n",
       "879               0.0   0.0  0.0   0.0  \n",
       "889               0.0   0.0  0.0   0.0  \n",
       "\n",
       "[891 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_data = normalized_data[normalized_data.Survived.notna()]\n",
    "normalized_test_data = normalized_data[normalized_data.Survived.isna()]\n",
    "normalized_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/40\n",
      "713/713 [==============================] - 0s 314us/step - loss: 0.5914 - acc: 0.7630 - val_loss: 0.5217 - val_acc: 0.8034\n",
      "Epoch 2/40\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.4991 - acc: 0.8022 - val_loss: 0.4784 - val_acc: 0.8202\n",
      "Epoch 3/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4712 - acc: 0.8022 - val_loss: 0.4696 - val_acc: 0.8034\n",
      "Epoch 4/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4572 - acc: 0.8022 - val_loss: 0.4621 - val_acc: 0.8146\n",
      "Epoch 5/40\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.4483 - acc: 0.8065 - val_loss: 0.4638 - val_acc: 0.8090\n",
      "Epoch 6/40\n",
      "713/713 [==============================] - 0s 163us/step - loss: 0.4421 - acc: 0.8093 - val_loss: 0.4643 - val_acc: 0.8090\n",
      "Epoch 7/40\n",
      "713/713 [==============================] - 0s 120us/step - loss: 0.4365 - acc: 0.8050 - val_loss: 0.4620 - val_acc: 0.8146\n",
      "Epoch 8/40\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4319 - acc: 0.8093 - val_loss: 0.4692 - val_acc: 0.8034\n",
      "Epoch 9/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4273 - acc: 0.8093 - val_loss: 0.4595 - val_acc: 0.7978\n",
      "Epoch 10/40\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4247 - acc: 0.8149 - val_loss: 0.4642 - val_acc: 0.7978\n",
      "Epoch 11/40\n",
      "713/713 [==============================] - 0s 151us/step - loss: 0.4205 - acc: 0.8163 - val_loss: 0.4609 - val_acc: 0.8146\n",
      "Epoch 12/40\n",
      "713/713 [==============================] - 0s 114us/step - loss: 0.4170 - acc: 0.8219 - val_loss: 0.4622 - val_acc: 0.7978\n",
      "Epoch 13/40\n",
      "713/713 [==============================] - 0s 200us/step - loss: 0.4145 - acc: 0.8219 - val_loss: 0.4612 - val_acc: 0.7978\n",
      "Epoch 14/40\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4109 - acc: 0.8163 - val_loss: 0.4579 - val_acc: 0.7921\n",
      "Epoch 15/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4081 - acc: 0.8149 - val_loss: 0.4600 - val_acc: 0.7978\n",
      "Epoch 16/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4059 - acc: 0.8191 - val_loss: 0.4633 - val_acc: 0.8034\n",
      "Epoch 17/40\n",
      "713/713 [==============================] - 0s 136us/step - loss: 0.4012 - acc: 0.8219 - val_loss: 0.4534 - val_acc: 0.7978\n",
      "Epoch 18/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4001 - acc: 0.8373 - val_loss: 0.4609 - val_acc: 0.7921\n",
      "Epoch 19/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3982 - acc: 0.8331 - val_loss: 0.4570 - val_acc: 0.7921\n",
      "Epoch 20/40\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3966 - acc: 0.8317 - val_loss: 0.4588 - val_acc: 0.8034\n",
      "Epoch 21/40\n",
      "713/713 [==============================] - 0s 164us/step - loss: 0.3945 - acc: 0.8247 - val_loss: 0.4566 - val_acc: 0.7921\n",
      "Epoch 22/40\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3920 - acc: 0.8345 - val_loss: 0.4619 - val_acc: 0.8258\n",
      "Epoch 23/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3899 - acc: 0.8345 - val_loss: 0.4553 - val_acc: 0.7865\n",
      "Epoch 24/40\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3890 - acc: 0.8373 - val_loss: 0.4566 - val_acc: 0.7978\n",
      "Epoch 25/40\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.3882 - acc: 0.8387 - val_loss: 0.4589 - val_acc: 0.8034\n",
      "Epoch 26/40\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3849 - acc: 0.8429 - val_loss: 0.4542 - val_acc: 0.7865\n",
      "Epoch 27/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3855 - acc: 0.8401 - val_loss: 0.4591 - val_acc: 0.8090\n",
      "Epoch 28/40\n",
      "713/713 [==============================] - 0s 116us/step - loss: 0.3824 - acc: 0.8457 - val_loss: 0.4713 - val_acc: 0.7978\n",
      "Epoch 29/40\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.3827 - acc: 0.8471 - val_loss: 0.4665 - val_acc: 0.7921\n",
      "Epoch 30/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3814 - acc: 0.8485 - val_loss: 0.4608 - val_acc: 0.8090\n",
      "Epoch 31/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3803 - acc: 0.8485 - val_loss: 0.4666 - val_acc: 0.7865\n",
      "Epoch 32/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3785 - acc: 0.8457 - val_loss: 0.4622 - val_acc: 0.7978\n",
      "Epoch 33/40\n",
      "713/713 [==============================] - 0s 142us/step - loss: 0.3775 - acc: 0.8513 - val_loss: 0.4727 - val_acc: 0.7753\n",
      "Epoch 34/40\n",
      "713/713 [==============================] - 0s 149us/step - loss: 0.3751 - acc: 0.8457 - val_loss: 0.4579 - val_acc: 0.8034\n",
      "Epoch 35/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3765 - acc: 0.8499 - val_loss: 0.4683 - val_acc: 0.8146\n",
      "Epoch 36/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3757 - acc: 0.8513 - val_loss: 0.4585 - val_acc: 0.8034\n",
      "Epoch 37/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3764 - acc: 0.8513 - val_loss: 0.4666 - val_acc: 0.7921\n",
      "Epoch 38/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3730 - acc: 0.8499 - val_loss: 0.4760 - val_acc: 0.7865\n",
      "Epoch 39/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3725 - acc: 0.8471 - val_loss: 0.4606 - val_acc: 0.7921\n",
      "Epoch 40/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3730 - acc: 0.8527 - val_loss: 0.4676 - val_acc: 0.7978\n",
      "processing fold # 1\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/40\n",
      "713/713 [==============================] - 0s 298us/step - loss: 0.5992 - acc: 0.6564 - val_loss: 0.5879 - val_acc: 0.6573\n",
      "Epoch 2/40\n",
      "713/713 [==============================] - 0s 115us/step - loss: 0.5415 - acc: 0.7475 - val_loss: 0.5499 - val_acc: 0.7753\n",
      "Epoch 3/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.5079 - acc: 0.7966 - val_loss: 0.5214 - val_acc: 0.7865\n",
      "Epoch 4/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4852 - acc: 0.7910 - val_loss: 0.5026 - val_acc: 0.7921\n",
      "Epoch 5/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4699 - acc: 0.7938 - val_loss: 0.4906 - val_acc: 0.7921\n",
      "Epoch 6/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.4595 - acc: 0.7938 - val_loss: 0.4833 - val_acc: 0.7921\n",
      "Epoch 7/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.4524 - acc: 0.7966 - val_loss: 0.4796 - val_acc: 0.7865\n",
      "Epoch 8/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4448 - acc: 0.8008 - val_loss: 0.4743 - val_acc: 0.7809\n",
      "Epoch 9/40\n",
      "713/713 [==============================] - 0s 120us/step - loss: 0.4411 - acc: 0.7994 - val_loss: 0.4713 - val_acc: 0.7865\n",
      "Epoch 10/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4364 - acc: 0.8050 - val_loss: 0.4686 - val_acc: 0.7921\n",
      "Epoch 11/40\n",
      "713/713 [==============================] - 0s 119us/step - loss: 0.4335 - acc: 0.8050 - val_loss: 0.4652 - val_acc: 0.7978\n",
      "Epoch 12/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4285 - acc: 0.8121 - val_loss: 0.4638 - val_acc: 0.7978\n",
      "Epoch 13/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4266 - acc: 0.8079 - val_loss: 0.4620 - val_acc: 0.7978\n",
      "Epoch 14/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.4234 - acc: 0.8121 - val_loss: 0.4596 - val_acc: 0.7978\n",
      "Epoch 15/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4213 - acc: 0.8163 - val_loss: 0.4577 - val_acc: 0.7978\n",
      "Epoch 16/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4188 - acc: 0.8135 - val_loss: 0.4580 - val_acc: 0.7978\n",
      "Epoch 17/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4156 - acc: 0.8135 - val_loss: 0.4573 - val_acc: 0.7978\n",
      "Epoch 18/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4148 - acc: 0.8233 - val_loss: 0.4545 - val_acc: 0.7921\n",
      "Epoch 19/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.4120 - acc: 0.8233 - val_loss: 0.4532 - val_acc: 0.7921\n",
      "Epoch 20/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4096 - acc: 0.8233 - val_loss: 0.4510 - val_acc: 0.7921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4066 - acc: 0.8275 - val_loss: 0.4499 - val_acc: 0.7978\n",
      "Epoch 22/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.4060 - acc: 0.8191 - val_loss: 0.4502 - val_acc: 0.7978\n",
      "Epoch 23/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.4043 - acc: 0.8233 - val_loss: 0.4500 - val_acc: 0.8034\n",
      "Epoch 24/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4025 - acc: 0.8275 - val_loss: 0.4484 - val_acc: 0.7978\n",
      "Epoch 25/40\n",
      "713/713 [==============================] - 0s 120us/step - loss: 0.4017 - acc: 0.8289 - val_loss: 0.4462 - val_acc: 0.7921\n",
      "Epoch 26/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3994 - acc: 0.8289 - val_loss: 0.4464 - val_acc: 0.7921\n",
      "Epoch 27/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3963 - acc: 0.8317 - val_loss: 0.4538 - val_acc: 0.8034\n",
      "Epoch 28/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3977 - acc: 0.8303 - val_loss: 0.4458 - val_acc: 0.8034\n",
      "Epoch 29/40\n",
      "713/713 [==============================] - 0s 117us/step - loss: 0.3968 - acc: 0.8261 - val_loss: 0.4468 - val_acc: 0.8034\n",
      "Epoch 30/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3944 - acc: 0.8331 - val_loss: 0.4465 - val_acc: 0.8034\n",
      "Epoch 31/40\n",
      "713/713 [==============================] - 0s 112us/step - loss: 0.3939 - acc: 0.8387 - val_loss: 0.4432 - val_acc: 0.8090\n",
      "Epoch 32/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3910 - acc: 0.8303 - val_loss: 0.4494 - val_acc: 0.8034\n",
      "Epoch 33/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3898 - acc: 0.8303 - val_loss: 0.4535 - val_acc: 0.7978\n",
      "Epoch 34/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3916 - acc: 0.8359 - val_loss: 0.4443 - val_acc: 0.8146\n",
      "Epoch 35/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3872 - acc: 0.8359 - val_loss: 0.4525 - val_acc: 0.8034\n",
      "Epoch 36/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.3900 - acc: 0.8303 - val_loss: 0.4467 - val_acc: 0.8090\n",
      "Epoch 37/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3887 - acc: 0.8359 - val_loss: 0.4445 - val_acc: 0.8202\n",
      "Epoch 38/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3868 - acc: 0.8373 - val_loss: 0.4460 - val_acc: 0.8090\n",
      "Epoch 39/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3868 - acc: 0.8373 - val_loss: 0.4451 - val_acc: 0.8146\n",
      "Epoch 40/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3851 - acc: 0.8359 - val_loss: 0.4493 - val_acc: 0.8090\n",
      "processing fold # 2\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/40\n",
      "713/713 [==============================] - 0s 286us/step - loss: 0.6569 - acc: 0.6648 - val_loss: 0.6377 - val_acc: 0.7191\n",
      "Epoch 2/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.5912 - acc: 0.7756 - val_loss: 0.5978 - val_acc: 0.7416\n",
      "Epoch 3/40\n",
      "713/713 [==============================] - 0s 118us/step - loss: 0.5340 - acc: 0.8008 - val_loss: 0.5640 - val_acc: 0.7416\n",
      "Epoch 4/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4839 - acc: 0.8008 - val_loss: 0.5369 - val_acc: 0.7416\n",
      "Epoch 5/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4585 - acc: 0.8008 - val_loss: 0.5301 - val_acc: 0.7416\n",
      "Epoch 6/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4478 - acc: 0.8036 - val_loss: 0.5264 - val_acc: 0.7416\n",
      "Epoch 7/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.4404 - acc: 0.8065 - val_loss: 0.5197 - val_acc: 0.7416\n",
      "Epoch 8/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.4344 - acc: 0.8065 - val_loss: 0.5173 - val_acc: 0.7416\n",
      "Epoch 9/40\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4302 - acc: 0.8065 - val_loss: 0.5114 - val_acc: 0.7416\n",
      "Epoch 10/40\n",
      "713/713 [==============================] - 0s 118us/step - loss: 0.4253 - acc: 0.8050 - val_loss: 0.5069 - val_acc: 0.7416\n",
      "Epoch 11/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4215 - acc: 0.8121 - val_loss: 0.5105 - val_acc: 0.7528\n",
      "Epoch 12/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.4178 - acc: 0.8219 - val_loss: 0.5125 - val_acc: 0.7584\n",
      "Epoch 13/40\n",
      "713/713 [==============================] - 0s 110us/step - loss: 0.4144 - acc: 0.8233 - val_loss: 0.5116 - val_acc: 0.7584\n",
      "Epoch 14/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4115 - acc: 0.8261 - val_loss: 0.5065 - val_acc: 0.7584\n",
      "Epoch 15/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4086 - acc: 0.8261 - val_loss: 0.4997 - val_acc: 0.7584\n",
      "Epoch 16/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4050 - acc: 0.8261 - val_loss: 0.4902 - val_acc: 0.7584\n",
      "Epoch 17/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4033 - acc: 0.8261 - val_loss: 0.4980 - val_acc: 0.7584\n",
      "Epoch 18/40\n",
      "713/713 [==============================] - 0s 116us/step - loss: 0.4019 - acc: 0.8219 - val_loss: 0.5001 - val_acc: 0.7584\n",
      "Epoch 19/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3986 - acc: 0.8289 - val_loss: 0.4938 - val_acc: 0.7697\n",
      "Epoch 20/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3960 - acc: 0.8359 - val_loss: 0.4904 - val_acc: 0.7640\n",
      "Epoch 21/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3957 - acc: 0.8289 - val_loss: 0.4954 - val_acc: 0.7697\n",
      "Epoch 22/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3908 - acc: 0.8289 - val_loss: 0.5141 - val_acc: 0.7360\n",
      "Epoch 23/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.3925 - acc: 0.8289 - val_loss: 0.4948 - val_acc: 0.7753\n",
      "Epoch 24/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3893 - acc: 0.8345 - val_loss: 0.5091 - val_acc: 0.7472\n",
      "Epoch 25/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3892 - acc: 0.8387 - val_loss: 0.4989 - val_acc: 0.7753\n",
      "Epoch 26/40\n",
      "713/713 [==============================] - 0s 119us/step - loss: 0.3874 - acc: 0.8401 - val_loss: 0.4916 - val_acc: 0.7809\n",
      "Epoch 27/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3864 - acc: 0.8443 - val_loss: 0.4981 - val_acc: 0.7697\n",
      "Epoch 28/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3857 - acc: 0.8387 - val_loss: 0.5017 - val_acc: 0.7584\n",
      "Epoch 29/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3827 - acc: 0.8415 - val_loss: 0.5142 - val_acc: 0.7528\n",
      "Epoch 30/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3836 - acc: 0.8457 - val_loss: 0.4947 - val_acc: 0.7697\n",
      "Epoch 31/40\n",
      "713/713 [==============================] - 0s 143us/step - loss: 0.3816 - acc: 0.8485 - val_loss: 0.4988 - val_acc: 0.7584\n",
      "Epoch 32/40\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.3808 - acc: 0.8429 - val_loss: 0.5042 - val_acc: 0.7584\n",
      "Epoch 33/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3799 - acc: 0.8457 - val_loss: 0.5093 - val_acc: 0.7584\n",
      "Epoch 34/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.3795 - acc: 0.8499 - val_loss: 0.5032 - val_acc: 0.7584\n",
      "Epoch 35/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3786 - acc: 0.8485 - val_loss: 0.5067 - val_acc: 0.7528\n",
      "Epoch 36/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3777 - acc: 0.8569 - val_loss: 0.5162 - val_acc: 0.7584\n",
      "Epoch 37/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3759 - acc: 0.8527 - val_loss: 0.5067 - val_acc: 0.7697\n",
      "Epoch 38/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3758 - acc: 0.8513 - val_loss: 0.5030 - val_acc: 0.7697\n",
      "Epoch 39/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.3741 - acc: 0.8513 - val_loss: 0.5206 - val_acc: 0.7584\n",
      "Epoch 40/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3739 - acc: 0.8555 - val_loss: 0.5241 - val_acc: 0.7584\n",
      "processing fold # 3\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 0s 294us/step - loss: 0.6335 - acc: 0.7265 - val_loss: 0.5688 - val_acc: 0.8258\n",
      "Epoch 2/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.5395 - acc: 0.7980 - val_loss: 0.4880 - val_acc: 0.8146\n",
      "Epoch 3/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.4855 - acc: 0.7994 - val_loss: 0.4461 - val_acc: 0.8090\n",
      "Epoch 4/40\n",
      "713/713 [==============================] - 0s 120us/step - loss: 0.4631 - acc: 0.7994 - val_loss: 0.4362 - val_acc: 0.8202\n",
      "Epoch 5/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4574 - acc: 0.8065 - val_loss: 0.4192 - val_acc: 0.8146\n",
      "Epoch 6/40\n",
      "713/713 [==============================] - 0s 110us/step - loss: 0.4468 - acc: 0.8093 - val_loss: 0.4124 - val_acc: 0.8090\n",
      "Epoch 7/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4436 - acc: 0.8079 - val_loss: 0.4055 - val_acc: 0.8146\n",
      "Epoch 8/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.4390 - acc: 0.8135 - val_loss: 0.4005 - val_acc: 0.8146\n",
      "Epoch 9/40\n",
      "713/713 [==============================] - 0s 117us/step - loss: 0.4336 - acc: 0.8163 - val_loss: 0.3959 - val_acc: 0.8202\n",
      "Epoch 10/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4301 - acc: 0.8149 - val_loss: 0.3930 - val_acc: 0.8202\n",
      "Epoch 11/40\n",
      "713/713 [==============================] - 0s 140us/step - loss: 0.4271 - acc: 0.8191 - val_loss: 0.3907 - val_acc: 0.8202\n",
      "Epoch 12/40\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.4247 - acc: 0.8149 - val_loss: 0.3918 - val_acc: 0.8202\n",
      "Epoch 13/40\n",
      "713/713 [==============================] - 0s 139us/step - loss: 0.4233 - acc: 0.8163 - val_loss: 0.3929 - val_acc: 0.8202\n",
      "Epoch 14/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4211 - acc: 0.8163 - val_loss: 0.3885 - val_acc: 0.8146\n",
      "Epoch 15/40\n",
      "713/713 [==============================] - 0s 116us/step - loss: 0.4187 - acc: 0.8205 - val_loss: 0.3895 - val_acc: 0.8146\n",
      "Epoch 16/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4160 - acc: 0.8191 - val_loss: 0.3923 - val_acc: 0.8146\n",
      "Epoch 17/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4158 - acc: 0.8275 - val_loss: 0.3890 - val_acc: 0.8146\n",
      "Epoch 18/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4147 - acc: 0.8247 - val_loss: 0.3902 - val_acc: 0.8146\n",
      "Epoch 19/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4132 - acc: 0.8191 - val_loss: 0.3932 - val_acc: 0.8146\n",
      "Epoch 20/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4122 - acc: 0.8247 - val_loss: 0.3931 - val_acc: 0.8146\n",
      "Epoch 21/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4115 - acc: 0.8219 - val_loss: 0.3926 - val_acc: 0.8146\n",
      "Epoch 22/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4089 - acc: 0.8289 - val_loss: 0.3925 - val_acc: 0.8146\n",
      "Epoch 23/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.4087 - acc: 0.8289 - val_loss: 0.3914 - val_acc: 0.8202\n",
      "Epoch 24/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4075 - acc: 0.8289 - val_loss: 0.3996 - val_acc: 0.8258\n",
      "Epoch 25/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4086 - acc: 0.8317 - val_loss: 0.3949 - val_acc: 0.8146\n",
      "Epoch 26/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.4063 - acc: 0.8331 - val_loss: 0.3951 - val_acc: 0.8258\n",
      "Epoch 27/40\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4059 - acc: 0.8317 - val_loss: 0.3953 - val_acc: 0.8258\n",
      "Epoch 28/40\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4048 - acc: 0.8359 - val_loss: 0.3987 - val_acc: 0.8315\n",
      "Epoch 29/40\n",
      "713/713 [==============================] - 0s 120us/step - loss: 0.4036 - acc: 0.8345 - val_loss: 0.3961 - val_acc: 0.8315\n",
      "Epoch 30/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4034 - acc: 0.8317 - val_loss: 0.3973 - val_acc: 0.8427\n",
      "Epoch 31/40\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4022 - acc: 0.8345 - val_loss: 0.4005 - val_acc: 0.8315\n",
      "Epoch 32/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4026 - acc: 0.8331 - val_loss: 0.3990 - val_acc: 0.8315\n",
      "Epoch 33/40\n",
      "713/713 [==============================] - 0s 141us/step - loss: 0.4007 - acc: 0.8401 - val_loss: 0.4002 - val_acc: 0.8315\n",
      "Epoch 34/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4007 - acc: 0.8415 - val_loss: 0.4014 - val_acc: 0.8315\n",
      "Epoch 35/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3995 - acc: 0.8387 - val_loss: 0.4008 - val_acc: 0.8315\n",
      "Epoch 36/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3994 - acc: 0.8401 - val_loss: 0.4017 - val_acc: 0.8315\n",
      "Epoch 37/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3990 - acc: 0.8415 - val_loss: 0.3993 - val_acc: 0.8483\n",
      "Epoch 38/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.3984 - acc: 0.8387 - val_loss: 0.4021 - val_acc: 0.8371\n",
      "Epoch 39/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3969 - acc: 0.8429 - val_loss: 0.4000 - val_acc: 0.8483\n",
      "Epoch 40/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.3972 - acc: 0.8443 - val_loss: 0.4013 - val_acc: 0.8483\n",
      "processing fold # 4\n",
      "Train on 713 samples, validate on 178 samples\n",
      "Epoch 1/40\n",
      "713/713 [==============================] - 0s 282us/step - loss: 0.6023 - acc: 0.7433 - val_loss: 0.5535 - val_acc: 0.8371\n",
      "Epoch 2/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.5264 - acc: 0.7882 - val_loss: 0.4956 - val_acc: 0.8315\n",
      "Epoch 3/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.4907 - acc: 0.7868 - val_loss: 0.4724 - val_acc: 0.8258\n",
      "Epoch 4/40\n",
      "713/713 [==============================] - 0s 118us/step - loss: 0.4693 - acc: 0.7896 - val_loss: 0.4456 - val_acc: 0.8258\n",
      "Epoch 5/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4567 - acc: 0.7910 - val_loss: 0.4356 - val_acc: 0.8315\n",
      "Epoch 6/40\n",
      "713/713 [==============================] - 0s 124us/step - loss: 0.4486 - acc: 0.7952 - val_loss: 0.4313 - val_acc: 0.8258\n",
      "Epoch 7/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4415 - acc: 0.8008 - val_loss: 0.4313 - val_acc: 0.8258\n",
      "Epoch 8/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.4351 - acc: 0.8065 - val_loss: 0.4325 - val_acc: 0.8202\n",
      "Epoch 9/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.4322 - acc: 0.7966 - val_loss: 0.4260 - val_acc: 0.8371\n",
      "Epoch 10/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.4274 - acc: 0.8065 - val_loss: 0.4212 - val_acc: 0.8258\n",
      "Epoch 11/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4230 - acc: 0.8121 - val_loss: 0.4244 - val_acc: 0.8539\n",
      "Epoch 12/40\n",
      "713/713 [==============================] - 0s 128us/step - loss: 0.4202 - acc: 0.8135 - val_loss: 0.4217 - val_acc: 0.8371\n",
      "Epoch 13/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.4153 - acc: 0.8121 - val_loss: 0.4225 - val_acc: 0.7640\n",
      "Epoch 14/40\n",
      "713/713 [==============================] - 0s 135us/step - loss: 0.4144 - acc: 0.8261 - val_loss: 0.4194 - val_acc: 0.7753\n",
      "Epoch 15/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.4101 - acc: 0.8163 - val_loss: 0.4187 - val_acc: 0.7697\n",
      "Epoch 16/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4086 - acc: 0.8275 - val_loss: 0.4207 - val_acc: 0.7697\n",
      "Epoch 17/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.4073 - acc: 0.8261 - val_loss: 0.4185 - val_acc: 0.7697\n",
      "Epoch 18/40\n",
      "713/713 [==============================] - 0s 138us/step - loss: 0.4041 - acc: 0.8303 - val_loss: 0.4196 - val_acc: 0.7753\n",
      "Epoch 19/40\n",
      "713/713 [==============================] - 0s 130us/step - loss: 0.4018 - acc: 0.8261 - val_loss: 0.4193 - val_acc: 0.7697\n",
      "Epoch 20/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.4011 - acc: 0.8317 - val_loss: 0.4136 - val_acc: 0.7640\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 0s 123us/step - loss: 0.3992 - acc: 0.8345 - val_loss: 0.4137 - val_acc: 0.8315\n",
      "Epoch 22/40\n",
      "713/713 [==============================] - 0s 131us/step - loss: 0.3988 - acc: 0.8289 - val_loss: 0.4132 - val_acc: 0.8315\n",
      "Epoch 23/40\n",
      "713/713 [==============================] - 0s 120us/step - loss: 0.3950 - acc: 0.8303 - val_loss: 0.4138 - val_acc: 0.7809\n",
      "Epoch 24/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3954 - acc: 0.8247 - val_loss: 0.4145 - val_acc: 0.8315\n",
      "Epoch 25/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.3932 - acc: 0.8247 - val_loss: 0.4121 - val_acc: 0.8315\n",
      "Epoch 26/40\n",
      "713/713 [==============================] - 0s 129us/step - loss: 0.3930 - acc: 0.8261 - val_loss: 0.4072 - val_acc: 0.8371\n",
      "Epoch 27/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3934 - acc: 0.8303 - val_loss: 0.4082 - val_acc: 0.8371\n",
      "Epoch 28/40\n",
      "713/713 [==============================] - 0s 125us/step - loss: 0.3909 - acc: 0.8317 - val_loss: 0.4103 - val_acc: 0.8315\n",
      "Epoch 29/40\n",
      "713/713 [==============================] - 0s 121us/step - loss: 0.3902 - acc: 0.8331 - val_loss: 0.4108 - val_acc: 0.7753\n",
      "Epoch 30/40\n",
      "713/713 [==============================] - 0s 133us/step - loss: 0.3872 - acc: 0.8387 - val_loss: 0.4091 - val_acc: 0.8371\n",
      "Epoch 31/40\n",
      "713/713 [==============================] - 0s 122us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.4080 - val_acc: 0.8371\n",
      "Epoch 32/40\n",
      "713/713 [==============================] - 0s 132us/step - loss: 0.3876 - acc: 0.8359 - val_loss: 0.4083 - val_acc: 0.8371\n",
      "Epoch 33/40\n",
      "713/713 [==============================] - 0s 114us/step - loss: 0.3859 - acc: 0.8415 - val_loss: 0.4087 - val_acc: 0.8315\n",
      "Epoch 34/40\n",
      "713/713 [==============================] - 0s 134us/step - loss: 0.3856 - acc: 0.8373 - val_loss: 0.4077 - val_acc: 0.8315\n",
      "Epoch 35/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3859 - acc: 0.8317 - val_loss: 0.4093 - val_acc: 0.8371\n",
      "Epoch 36/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3847 - acc: 0.8387 - val_loss: 0.4068 - val_acc: 0.8371\n",
      "Epoch 37/40\n",
      "713/713 [==============================] - 0s 127us/step - loss: 0.3840 - acc: 0.8387 - val_loss: 0.4056 - val_acc: 0.8371\n",
      "Epoch 38/40\n",
      "713/713 [==============================] - 0s 137us/step - loss: 0.3830 - acc: 0.8387 - val_loss: 0.4052 - val_acc: 0.8371\n",
      "Epoch 39/40\n",
      "713/713 [==============================] - 0s 123us/step - loss: 0.3830 - acc: 0.8443 - val_loss: 0.4042 - val_acc: 0.8371\n",
      "Epoch 40/40\n",
      "713/713 [==============================] - 0s 126us/step - loss: 0.3832 - acc: 0.8331 - val_loss: 0.4042 - val_acc: 0.8371\n"
     ]
    }
   ],
   "source": [
    "x_train = normalized_train_data.drop([\"Survived\"], axis=1).values\n",
    "y_train = normalized_train_data[\"Survived\"].values\n",
    "\n",
    "number_of_epochs = 40\n",
    "number_of_folds = 5\n",
    "number_of_samples = len(x_train) // number_of_folds\n",
    "\n",
    "all_histories = []\n",
    "\n",
    "for i in range(number_of_folds):\n",
    "    print(\"processing fold #\", i)\n",
    "    \n",
    "    partial_x_train = np.concatenate([x_train[:i*number_of_samples],\n",
    "                                          x_train[(i+1)*number_of_samples:]])\n",
    "    parital_y_train = np.concatenate([y_train[:i*number_of_samples],\n",
    "                                          y_train[(i+1)*number_of_samples:]])\n",
    "    \n",
    "    partial_x_validation = x_train[i*number_of_samples:(i+1)*number_of_samples]\n",
    "    partial_y_validation = y_train[i*number_of_samples:(i+1)*number_of_samples]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(x_train.shape[1], activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
    "    model.add(layers.Dense(12, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"acc\"])\n",
    "\n",
    "    history = model.fit(partial_x_train,\n",
    "                        parital_y_train,\n",
    "                        epochs=number_of_epochs,\n",
    "                        batch_size=16,\n",
    "                        validation_data=[partial_x_validation,partial_y_validation])\n",
    "    all_histories.append(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "loss_values = [np.mean([x[\"loss\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "val_loss_values = [np.mean([x[\"val_loss\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\", color=\"red\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc_values = [np.mean([x[\"acc\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "val_acc_values = [np.mean([x[\"val_acc\"][i] for x in all_histories]) for i in range(number_of_epochs)]\n",
    "\n",
    "plt.plot(epochs, acc_values, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc_values, \"b\", label=\"Validation acc\", color=\"red\")\n",
    "plt.title(\"Training and validation acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 0\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1\n",
       "...               ...\n",
       "1300                1\n",
       "1302                1\n",
       "1305                0\n",
       "1308                0\n",
       "1309                1\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(normalized_test_data.drop([\"Survived\"], axis=1))\n",
    "results = pd.DataFrame(results, columns=[\"Survived\"], index=normalized_test_data.index)\n",
    "\n",
    "results.loc[results.Survived < 0.5, [\"Survived\"]] = 0\n",
    "results.loc[results.Survived >= 0.5, [\"Survived\"]] = 1\n",
    "results = results.fillna(0)\n",
    "results.Survived = results.Survived.astype(int)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"Output/my_prediction.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with genderr submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example</th>\n",
       "      <th>MyPrediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>928</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>964</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1086</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1231</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1257</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Example  MyPrediction\n",
       "PassengerId                       \n",
       "893                1             0\n",
       "913                0             1\n",
       "925                1             0\n",
       "926                0             1\n",
       "928                1             0\n",
       "956                0             1\n",
       "960                0             1\n",
       "964                1             0\n",
       "967                0             1\n",
       "972                0             1\n",
       "980                1             0\n",
       "981                0             1\n",
       "986                0             1\n",
       "1010               0             1\n",
       "1019               1             0\n",
       "1023               0             1\n",
       "1024               1             0\n",
       "1032               1             0\n",
       "1053               0             1\n",
       "1080               1             0\n",
       "1086               0             1\n",
       "1088               0             1\n",
       "1093               0             1\n",
       "1094               0             1\n",
       "1106               1             0\n",
       "1144               0             1\n",
       "1165               1             0\n",
       "1173               0             1\n",
       "1199               0             1\n",
       "1201               1             0\n",
       "1231               0             1\n",
       "1257               1             0\n",
       "1268               1             0\n",
       "1282               0             1\n",
       "1284               0             1\n",
       "1295               0             1\n",
       "1304               1             0\n",
       "1309               0             1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.read_csv(\"Dataset/gender_submission.csv\", index_col=0)\n",
    "# compare = pd.read_csv(\"7799.csv\", index_col=0)\n",
    "compare = compare.rename(columns={\"Survived\": \"Example\"})\n",
    "compare = pd.concat([compare, results], axis=1)\n",
    "compare = compare.rename(columns={\"Survived\": \"MyPrediction\"})\n",
    "compare[compare.Example != compare.MyPrediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
