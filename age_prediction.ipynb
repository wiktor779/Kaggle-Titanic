{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1305              NaN     1.0       NaN    0.0  0.000000  0.015713     0.0   \n",
       "1306              NaN     0.0  0.484795    0.0  0.000000  0.212559     1.0   \n",
       "1307              NaN     1.0  0.478512    0.0  0.000000  0.014151     0.0   \n",
       "1308              NaN     1.0       NaN    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0       NaN    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0    0.0     1.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1306          0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1307          1.0  0.0  0.0  ...         1.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1306              0.0   0.0  0.0   0.0  \n",
       "1307              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[1309 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "normalized_data = pd.read_csv(\"normalized_data.csv\", index_col=0)\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Survived', 418),\n",
       " ('Age', 263),\n",
       " ('Pclass', 0),\n",
       " ('SibSp', 0),\n",
       " ('Parch', 0),\n",
       " ('Fare', 0),\n",
       " ('female', 0),\n",
       " ('male', 0),\n",
       " ('C', 0),\n",
       " ('Q', 0),\n",
       " ('S', 0),\n",
       " ('Mr', 0),\n",
       " ('Miss', 0),\n",
       " ('Mrs', 0),\n",
       " ('PC', 0),\n",
       " ('C.A.', 0),\n",
       " ('SOTON/O.Q.', 0),\n",
       " ('2.', 0),\n",
       " ('W./C.', 0),\n",
       " ('STON/O', 0),\n",
       " ('CA.', 0),\n",
       " ('A/5', 0),\n",
       " ('SC/PARIS', 0),\n",
       " ('2343', 0),\n",
       " ('CA', 0),\n",
       " ('A/5.', 0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_values = [(label, normalized_data[label].isnull().sum()) for label in normalized_data.columns.values]\n",
    "sorted(empty_values, reverse=True, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate samples with and without age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_with_age = normalized_data[normalized_data.Age.notna()]\n",
    "samples_without_age = normalized_data[normalized_data.Age.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model for age prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 267us/step - loss: 0.0525 - mae: 0.1757 - val_loss: 0.0291 - val_mae: 0.1342\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0269 - mae: 0.1295 - val_loss: 0.0250 - val_mae: 0.1248\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0242 - mae: 0.1213 - val_loss: 0.0238 - val_mae: 0.1184\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0227 - mae: 0.1167 - val_loss: 0.0233 - val_mae: 0.1168\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0217 - mae: 0.1140 - val_loss: 0.0243 - val_mae: 0.1165\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0216 - mae: 0.1128 - val_loss: 0.0240 - val_mae: 0.1219\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0213 - mae: 0.1118 - val_loss: 0.0235 - val_mae: 0.1199\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 159us/step - loss: 0.0210 - mae: 0.1111 - val_loss: 0.0230 - val_mae: 0.1180\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 184us/step - loss: 0.0210 - mae: 0.1112 - val_loss: 0.0228 - val_mae: 0.1154\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 137us/step - loss: 0.0206 - mae: 0.1099 - val_loss: 0.0231 - val_mae: 0.1183\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0205 - mae: 0.1096 - val_loss: 0.0228 - val_mae: 0.1160\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0204 - mae: 0.1091 - val_loss: 0.0227 - val_mae: 0.1169\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0202 - mae: 0.1084 - val_loss: 0.0235 - val_mae: 0.1214\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 144us/step - loss: 0.0201 - mae: 0.1083 - val_loss: 0.0226 - val_mae: 0.1169\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0202 - mae: 0.1090 - val_loss: 0.0232 - val_mae: 0.1199\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0199 - mae: 0.1081 - val_loss: 0.0221 - val_mae: 0.1135\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0198 - mae: 0.1075 - val_loss: 0.0227 - val_mae: 0.1173\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0197 - mae: 0.1065 - val_loss: 0.0231 - val_mae: 0.1192\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0197 - mae: 0.1070 - val_loss: 0.0225 - val_mae: 0.1139\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0195 - mae: 0.1063 - val_loss: 0.0223 - val_mae: 0.1134\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0196 - mae: 0.1065 - val_loss: 0.0226 - val_mae: 0.1167\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0195 - mae: 0.1062 - val_loss: 0.0224 - val_mae: 0.1167\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0192 - mae: 0.1049 - val_loss: 0.0221 - val_mae: 0.1124\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0193 - mae: 0.1055 - val_loss: 0.0227 - val_mae: 0.1178\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0192 - mae: 0.1060 - val_loss: 0.0233 - val_mae: 0.1209\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0191 - mae: 0.1049 - val_loss: 0.0219 - val_mae: 0.1132\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 138us/step - loss: 0.0191 - mae: 0.1045 - val_loss: 0.0226 - val_mae: 0.1179\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0188 - mae: 0.1040 - val_loss: 0.0216 - val_mae: 0.1119\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0190 - mae: 0.1051 - val_loss: 0.0221 - val_mae: 0.1124\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0190 - mae: 0.1043 - val_loss: 0.0216 - val_mae: 0.1126\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 143us/step - loss: 0.0187 - mae: 0.1038 - val_loss: 0.0216 - val_mae: 0.1121\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 142us/step - loss: 0.0188 - mae: 0.1039 - val_loss: 0.0220 - val_mae: 0.1140\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0188 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1216\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0186 - mae: 0.1034 - val_loss: 0.0217 - val_mae: 0.1123\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0185 - mae: 0.1032 - val_loss: 0.0216 - val_mae: 0.1131\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0187 - mae: 0.1042 - val_loss: 0.0219 - val_mae: 0.1126\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0183 - mae: 0.1033 - val_loss: 0.0221 - val_mae: 0.1156\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0184 - mae: 0.1027 - val_loss: 0.0212 - val_mae: 0.1122\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0185 - mae: 0.1029 - val_loss: 0.0213 - val_mae: 0.1112\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0183 - mae: 0.1027 - val_loss: 0.0212 - val_mae: 0.1106\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.1025 - val_loss: 0.0211 - val_mae: 0.1104\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0183 - mae: 0.1016 - val_loss: 0.0212 - val_mae: 0.1121\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0182 - mae: 0.1020 - val_loss: 0.0217 - val_mae: 0.1137\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0181 - mae: 0.1025 - val_loss: 0.0211 - val_mae: 0.1098\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.1016 - val_loss: 0.0207 - val_mae: 0.1102\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0180 - mae: 0.1023 - val_loss: 0.0211 - val_mae: 0.1104\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0178 - mae: 0.1007 - val_loss: 0.0211 - val_mae: 0.1108\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0179 - mae: 0.1014 - val_loss: 0.0212 - val_mae: 0.1107\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0180 - mae: 0.1014 - val_loss: 0.0209 - val_mae: 0.1108\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0179 - mae: 0.1014 - val_loss: 0.0210 - val_mae: 0.1101\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0177 - mae: 0.1002 - val_loss: 0.0209 - val_mae: 0.1103\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0178 - mae: 0.1006 - val_loss: 0.0211 - val_mae: 0.1110\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0175 - mae: 0.0997 - val_loss: 0.0221 - val_mae: 0.1145\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.1006 - val_loss: 0.0216 - val_mae: 0.1139\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0177 - mae: 0.1013 - val_loss: 0.0208 - val_mae: 0.1104\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.1002 - val_loss: 0.0217 - val_mae: 0.1144\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.1007 - val_loss: 0.0228 - val_mae: 0.1188\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.1005 - val_loss: 0.0204 - val_mae: 0.1082\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0174 - mae: 0.0990 - val_loss: 0.0207 - val_mae: 0.1110\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0175 - mae: 0.1004 - val_loss: 0.0206 - val_mae: 0.1090\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.1004 - val_loss: 0.0203 - val_mae: 0.1090\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0174 - mae: 0.1002 - val_loss: 0.0203 - val_mae: 0.1084\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0997 - val_loss: 0.0204 - val_mae: 0.1089\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0174 - mae: 0.0992 - val_loss: 0.0202 - val_mae: 0.1098\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0171 - mae: 0.0989 - val_loss: 0.0228 - val_mae: 0.1193\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0172 - mae: 0.0997 - val_loss: 0.0204 - val_mae: 0.1090\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0172 - mae: 0.0991 - val_loss: 0.0204 - val_mae: 0.1085\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0994 - val_loss: 0.0202 - val_mae: 0.1096\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0172 - mae: 0.0986 - val_loss: 0.0200 - val_mae: 0.1073\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0989 - val_loss: 0.0202 - val_mae: 0.1079\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0169 - mae: 0.0985 - val_loss: 0.0201 - val_mae: 0.1072\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0170 - mae: 0.0989 - val_loss: 0.0198 - val_mae: 0.1066\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0168 - mae: 0.0981 - val_loss: 0.0203 - val_mae: 0.1092\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0171 - mae: 0.0988 - val_loss: 0.0202 - val_mae: 0.1091\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0976 - val_loss: 0.0212 - val_mae: 0.1135\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0983 - val_loss: 0.0199 - val_mae: 0.1080\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0167 - mae: 0.0985 - val_loss: 0.0199 - val_mae: 0.1075\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0975 - val_loss: 0.0206 - val_mae: 0.1110\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0169 - mae: 0.0978 - val_loss: 0.0199 - val_mae: 0.1068\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0167 - mae: 0.0971 - val_loss: 0.0212 - val_mae: 0.1140\n",
      "processing fold # 1\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 248us/step - loss: 0.0426 - mae: 0.1551 - val_loss: 0.0333 - val_mae: 0.1399\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0289 - mae: 0.1299 - val_loss: 0.0275 - val_mae: 0.1310\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0249 - mae: 0.1228 - val_loss: 0.0249 - val_mae: 0.1230\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 145us/step - loss: 0.0229 - mae: 0.1183 - val_loss: 0.0236 - val_mae: 0.1179\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 150us/step - loss: 0.0217 - mae: 0.1148 - val_loss: 0.0231 - val_mae: 0.1163\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 135us/step - loss: 0.0212 - mae: 0.1141 - val_loss: 0.0223 - val_mae: 0.1158\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0205 - mae: 0.1114 - val_loss: 0.0225 - val_mae: 0.1193\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0205 - mae: 0.1126 - val_loss: 0.0219 - val_mae: 0.1131\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0200 - mae: 0.1106 - val_loss: 0.0227 - val_mae: 0.1137\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0199 - mae: 0.1105 - val_loss: 0.0219 - val_mae: 0.1152\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0196 - mae: 0.1095 - val_loss: 0.0214 - val_mae: 0.1125\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.1075 - val_loss: 0.0222 - val_mae: 0.1180\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0195 - mae: 0.1092 - val_loss: 0.0228 - val_mae: 0.1196\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0191 - mae: 0.1079 - val_loss: 0.0226 - val_mae: 0.1124\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.1079 - val_loss: 0.0217 - val_mae: 0.1121\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0188 - mae: 0.1072 - val_loss: 0.0225 - val_mae: 0.1119\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0188 - mae: 0.1067 - val_loss: 0.0220 - val_mae: 0.1157\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0188 - mae: 0.1063 - val_loss: 0.0226 - val_mae: 0.1193\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0186 - mae: 0.1065 - val_loss: 0.0226 - val_mae: 0.1117\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0184 - mae: 0.1046 - val_loss: 0.0216 - val_mae: 0.1130\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0184 - mae: 0.1056 - val_loss: 0.0220 - val_mae: 0.1163\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0184 - mae: 0.1050 - val_loss: 0.0213 - val_mae: 0.1124\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0182 - mae: 0.1057 - val_loss: 0.0221 - val_mae: 0.1128\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0181 - mae: 0.1045 - val_loss: 0.0219 - val_mae: 0.1103\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0180 - mae: 0.1040 - val_loss: 0.0226 - val_mae: 0.1116\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 141us/step - loss: 0.0180 - mae: 0.1034 - val_loss: 0.0224 - val_mae: 0.1174\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 167us/step - loss: 0.0181 - mae: 0.1044 - val_loss: 0.0213 - val_mae: 0.1121\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0178 - mae: 0.1035 - val_loss: 0.0208 - val_mae: 0.1094\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 140us/step - loss: 0.0178 - mae: 0.1033 - val_loss: 0.0217 - val_mae: 0.1102\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0175 - mae: 0.1022 - val_loss: 0.0216 - val_mae: 0.1121\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0178 - mae: 0.1022 - val_loss: 0.0210 - val_mae: 0.1096\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.1022 - val_loss: 0.0249 - val_mae: 0.1163\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0177 - mae: 0.1021 - val_loss: 0.0215 - val_mae: 0.1127\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0175 - mae: 0.1018 - val_loss: 0.0212 - val_mae: 0.1088\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0176 - mae: 0.1013 - val_loss: 0.0209 - val_mae: 0.1094\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0174 - mae: 0.1015 - val_loss: 0.0219 - val_mae: 0.1160\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0174 - mae: 0.1019 - val_loss: 0.0208 - val_mae: 0.1082\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0174 - mae: 0.1008 - val_loss: 0.0214 - val_mae: 0.1084\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0173 - mae: 0.1003 - val_loss: 0.0211 - val_mae: 0.1127\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0172 - mae: 0.1007 - val_loss: 0.0207 - val_mae: 0.1086\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 128us/step - loss: 0.0171 - mae: 0.1005 - val_loss: 0.0210 - val_mae: 0.1120\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0173 - mae: 0.1006 - val_loss: 0.0208 - val_mae: 0.1105\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0169 - mae: 0.1000 - val_loss: 0.0209 - val_mae: 0.1102\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0169 - mae: 0.1003 - val_loss: 0.0219 - val_mae: 0.1089\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0171 - mae: 0.0996 - val_loss: 0.0207 - val_mae: 0.1097\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0169 - mae: 0.0999 - val_loss: 0.0212 - val_mae: 0.1082\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0170 - mae: 0.1001 - val_loss: 0.0203 - val_mae: 0.1091\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0167 - mae: 0.0988 - val_loss: 0.0203 - val_mae: 0.1064\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0169 - mae: 0.0986 - val_loss: 0.0201 - val_mae: 0.1076\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0169 - mae: 0.0987 - val_loss: 0.0230 - val_mae: 0.1202\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0167 - mae: 0.0985 - val_loss: 0.0206 - val_mae: 0.1094\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0166 - mae: 0.0984 - val_loss: 0.0203 - val_mae: 0.1082\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0990 - val_loss: 0.0206 - val_mae: 0.1071\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0165 - mae: 0.0973 - val_loss: 0.0206 - val_mae: 0.1080\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0980 - val_loss: 0.0201 - val_mae: 0.1072\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0165 - mae: 0.0980 - val_loss: 0.0199 - val_mae: 0.1072\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0163 - mae: 0.0977 - val_loss: 0.0202 - val_mae: 0.1068\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0165 - mae: 0.0975 - val_loss: 0.0205 - val_mae: 0.1063\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0164 - mae: 0.0970 - val_loss: 0.0199 - val_mae: 0.1062\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0164 - mae: 0.0975 - val_loss: 0.0200 - val_mae: 0.1063\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0163 - mae: 0.0969 - val_loss: 0.0218 - val_mae: 0.1167\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0163 - mae: 0.0975 - val_loss: 0.0206 - val_mae: 0.1059\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0162 - mae: 0.0969 - val_loss: 0.0207 - val_mae: 0.1062\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0966 - val_loss: 0.0206 - val_mae: 0.1109\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0166 - mae: 0.0985 - val_loss: 0.0205 - val_mae: 0.1056\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0163 - mae: 0.0967 - val_loss: 0.0201 - val_mae: 0.1067\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0163 - mae: 0.0975 - val_loss: 0.0202 - val_mae: 0.1064\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0162 - mae: 0.0965 - val_loss: 0.0198 - val_mae: 0.1057\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0163 - mae: 0.0971 - val_loss: 0.0199 - val_mae: 0.1060\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0162 - mae: 0.0968 - val_loss: 0.0199 - val_mae: 0.1057\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0160 - mae: 0.0960 - val_loss: 0.0208 - val_mae: 0.1065\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0164 - mae: 0.0977 - val_loss: 0.0203 - val_mae: 0.1091\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0162 - mae: 0.0971 - val_loss: 0.0199 - val_mae: 0.1052\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0162 - mae: 0.0968 - val_loss: 0.0198 - val_mae: 0.1071\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0161 - mae: 0.0967 - val_loss: 0.0199 - val_mae: 0.1075\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 141us/step - loss: 0.0160 - mae: 0.0957 - val_loss: 0.0206 - val_mae: 0.1109\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 159us/step - loss: 0.0161 - mae: 0.0968 - val_loss: 0.0198 - val_mae: 0.1047\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0163 - mae: 0.0968 - val_loss: 0.0199 - val_mae: 0.1090\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0160 - mae: 0.0960 - val_loss: 0.0218 - val_mae: 0.1086\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0161 - mae: 0.0962 - val_loss: 0.0199 - val_mae: 0.1068\n",
      "processing fold # 2\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 238us/step - loss: 0.0456 - mae: 0.1635 - val_loss: 0.0312 - val_mae: 0.1410\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0259 - mae: 0.1256 - val_loss: 0.0313 - val_mae: 0.1348\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0229 - mae: 0.1161 - val_loss: 0.0283 - val_mae: 0.1322\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0215 - mae: 0.1125 - val_loss: 0.0291 - val_mae: 0.1309\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0208 - mae: 0.1114 - val_loss: 0.0269 - val_mae: 0.1304\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0201 - mae: 0.1086 - val_loss: 0.0269 - val_mae: 0.1284\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0196 - mae: 0.1079 - val_loss: 0.0273 - val_mae: 0.1287\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0194 - mae: 0.1063 - val_loss: 0.0258 - val_mae: 0.1317\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0191 - mae: 0.1057 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0188 - mae: 0.1051 - val_loss: 0.0253 - val_mae: 0.1252\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 141us/step - loss: 0.0183 - mae: 0.1030 - val_loss: 0.0248 - val_mae: 0.1237\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0181 - mae: 0.1028 - val_loss: 0.0272 - val_mae: 0.1255\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0182 - mae: 0.1028 - val_loss: 0.0280 - val_mae: 0.1254\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 191us/step - loss: 0.0180 - mae: 0.1020 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0180 - mae: 0.1025 - val_loss: 0.0242 - val_mae: 0.1244\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0176 - mae: 0.1008 - val_loss: 0.0254 - val_mae: 0.1229\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0176 - mae: 0.1015 - val_loss: 0.0243 - val_mae: 0.1237\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0175 - mae: 0.1008 - val_loss: 0.0250 - val_mae: 0.1249\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0173 - mae: 0.1008 - val_loss: 0.0248 - val_mae: 0.1225\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0173 - mae: 0.0998 - val_loss: 0.0262 - val_mae: 0.1218\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 131us/step - loss: 0.0172 - mae: 0.0992 - val_loss: 0.0253 - val_mae: 0.1209\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0171 - mae: 0.0999 - val_loss: 0.0245 - val_mae: 0.1238\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1235\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0170 - mae: 0.0994 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0169 - mae: 0.0989 - val_loss: 0.0239 - val_mae: 0.1217\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0167 - mae: 0.0977 - val_loss: 0.0253 - val_mae: 0.1306\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0987 - val_loss: 0.0240 - val_mae: 0.1207\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0167 - mae: 0.0972 - val_loss: 0.0244 - val_mae: 0.1270\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0168 - mae: 0.0988 - val_loss: 0.0240 - val_mae: 0.1235\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 170us/step - loss: 0.0167 - mae: 0.0986 - val_loss: 0.0239 - val_mae: 0.1244\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 143us/step - loss: 0.0164 - mae: 0.0970 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0164 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1218\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0166 - mae: 0.0971 - val_loss: 0.0242 - val_mae: 0.1215\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0165 - mae: 0.0977 - val_loss: 0.0250 - val_mae: 0.1206\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0162 - mae: 0.0957 - val_loss: 0.0244 - val_mae: 0.1263\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 164us/step - loss: 0.0162 - mae: 0.0968 - val_loss: 0.0236 - val_mae: 0.1206\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0163 - mae: 0.0959 - val_loss: 0.0248 - val_mae: 0.1247\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0162 - mae: 0.0965 - val_loss: 0.0240 - val_mae: 0.1215\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0160 - mae: 0.0957 - val_loss: 0.0283 - val_mae: 0.1241\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0163 - mae: 0.0960 - val_loss: 0.0236 - val_mae: 0.1229\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0162 - mae: 0.0962 - val_loss: 0.0242 - val_mae: 0.1215\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0160 - mae: 0.0958 - val_loss: 0.0240 - val_mae: 0.1208\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0158 - mae: 0.0933 - val_loss: 0.0243 - val_mae: 0.1256\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0963 - val_loss: 0.0244 - val_mae: 0.1213\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0160 - mae: 0.0951 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0160 - mae: 0.0944 - val_loss: 0.0244 - val_mae: 0.1221\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0159 - mae: 0.0950 - val_loss: 0.0241 - val_mae: 0.1232\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0159 - mae: 0.0939 - val_loss: 0.0242 - val_mae: 0.1239\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0160 - mae: 0.0957 - val_loss: 0.0250 - val_mae: 0.1203\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0160 - mae: 0.0948 - val_loss: 0.0242 - val_mae: 0.1224\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0158 - mae: 0.0942 - val_loss: 0.0248 - val_mae: 0.1226\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0160 - mae: 0.0945 - val_loss: 0.0240 - val_mae: 0.1255\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0158 - mae: 0.0946 - val_loss: 0.0258 - val_mae: 0.1216\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0158 - mae: 0.0945 - val_loss: 0.0259 - val_mae: 0.1227\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0159 - mae: 0.0942 - val_loss: 0.0240 - val_mae: 0.1211\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0157 - mae: 0.0937 - val_loss: 0.0242 - val_mae: 0.1191\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0158 - mae: 0.0935 - val_loss: 0.0245 - val_mae: 0.1207\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0158 - mae: 0.0936 - val_loss: 0.0241 - val_mae: 0.1193\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0157 - mae: 0.0935 - val_loss: 0.0236 - val_mae: 0.1223\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 114us/step - loss: 0.0157 - mae: 0.0932 - val_loss: 0.0235 - val_mae: 0.1233\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0159 - mae: 0.0947 - val_loss: 0.0234 - val_mae: 0.1226\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 136us/step - loss: 0.0157 - mae: 0.0936 - val_loss: 0.0237 - val_mae: 0.1198\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0157 - mae: 0.0934 - val_loss: 0.0239 - val_mae: 0.1212\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0156 - mae: 0.0938 - val_loss: 0.0238 - val_mae: 0.1222\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0156 - mae: 0.0936 - val_loss: 0.0241 - val_mae: 0.1207\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0156 - mae: 0.0928 - val_loss: 0.0233 - val_mae: 0.1221\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0156 - mae: 0.0931 - val_loss: 0.0244 - val_mae: 0.1208\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0155 - mae: 0.0936 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0155 - mae: 0.0932 - val_loss: 0.0233 - val_mae: 0.1231\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0156 - mae: 0.0931 - val_loss: 0.0263 - val_mae: 0.1221\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0155 - mae: 0.0933 - val_loss: 0.0248 - val_mae: 0.1217\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0155 - mae: 0.0929 - val_loss: 0.0231 - val_mae: 0.1204\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0154 - mae: 0.0928 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0156 - mae: 0.0934 - val_loss: 0.0234 - val_mae: 0.1187\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0154 - mae: 0.0921 - val_loss: 0.0238 - val_mae: 0.1241\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0155 - mae: 0.0932 - val_loss: 0.0239 - val_mae: 0.1205\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0154 - mae: 0.0926 - val_loss: 0.0258 - val_mae: 0.1211\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 123us/step - loss: 0.0156 - mae: 0.0926 - val_loss: 0.0232 - val_mae: 0.1231\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0154 - mae: 0.0932 - val_loss: 0.0236 - val_mae: 0.1215\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0153 - mae: 0.0920 - val_loss: 0.0253 - val_mae: 0.1225\n",
      "processing fold # 3\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 232us/step - loss: 0.0592 - mae: 0.1868 - val_loss: 0.0355 - val_mae: 0.1467\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0296 - mae: 0.1350 - val_loss: 0.0273 - val_mae: 0.1226\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0256 - mae: 0.1246 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0241 - mae: 0.1208 - val_loss: 0.0233 - val_mae: 0.1140\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0234 - mae: 0.1194 - val_loss: 0.0225 - val_mae: 0.1135\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0228 - mae: 0.1179 - val_loss: 0.0220 - val_mae: 0.1130\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0220 - mae: 0.1157 - val_loss: 0.0220 - val_mae: 0.1146\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0217 - mae: 0.1158 - val_loss: 0.0221 - val_mae: 0.1118\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0215 - mae: 0.1145 - val_loss: 0.0235 - val_mae: 0.1202\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0211 - mae: 0.1142 - val_loss: 0.0223 - val_mae: 0.1097\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0208 - mae: 0.1128 - val_loss: 0.0221 - val_mae: 0.1093\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0208 - mae: 0.1123 - val_loss: 0.0224 - val_mae: 0.1096\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0204 - mae: 0.1110 - val_loss: 0.0217 - val_mae: 0.1085\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.1107 - val_loss: 0.0214 - val_mae: 0.1078\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0200 - mae: 0.1098 - val_loss: 0.0219 - val_mae: 0.1080\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0201 - mae: 0.1100 - val_loss: 0.0213 - val_mae: 0.1084\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0198 - mae: 0.1081 - val_loss: 0.0256 - val_mae: 0.1290\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.1094 - val_loss: 0.0218 - val_mae: 0.1095\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0195 - mae: 0.1086 - val_loss: 0.0227 - val_mae: 0.1173\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0194 - mae: 0.1082 - val_loss: 0.0226 - val_mae: 0.1153\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0194 - mae: 0.1069 - val_loss: 0.0222 - val_mae: 0.1072\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0193 - mae: 0.1075 - val_loss: 0.0210 - val_mae: 0.1075\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0189 - mae: 0.1066 - val_loss: 0.0215 - val_mae: 0.1113\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0191 - mae: 0.1063 - val_loss: 0.0218 - val_mae: 0.1122\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.1062 - val_loss: 0.0218 - val_mae: 0.1067\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0188 - mae: 0.1052 - val_loss: 0.0216 - val_mae: 0.1084\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0188 - mae: 0.1055 - val_loss: 0.0224 - val_mae: 0.1076\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0188 - mae: 0.1064 - val_loss: 0.0216 - val_mae: 0.1116\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0186 - mae: 0.1056 - val_loss: 0.0217 - val_mae: 0.1116\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0184 - mae: 0.1053 - val_loss: 0.0214 - val_mae: 0.1092\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0186 - mae: 0.1059 - val_loss: 0.0220 - val_mae: 0.1133\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0183 - mae: 0.1045 - val_loss: 0.0213 - val_mae: 0.1073\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.1047 - val_loss: 0.0219 - val_mae: 0.1066\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0184 - mae: 0.1044 - val_loss: 0.0220 - val_mae: 0.1122\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0181 - mae: 0.1039 - val_loss: 0.0230 - val_mae: 0.1081\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0183 - mae: 0.1035 - val_loss: 0.0218 - val_mae: 0.1068\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0179 - mae: 0.1027 - val_loss: 0.0219 - val_mae: 0.1105\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.1034 - val_loss: 0.0225 - val_mae: 0.1157\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0180 - mae: 0.1031 - val_loss: 0.0215 - val_mae: 0.1093\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.1029 - val_loss: 0.0215 - val_mae: 0.1100\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 116us/step - loss: 0.0178 - mae: 0.1015 - val_loss: 0.0221 - val_mae: 0.1112\n",
      "Epoch 42/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0177 - mae: 0.1019 - val_loss: 0.0218 - val_mae: 0.1102\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0177 - mae: 0.1029 - val_loss: 0.0227 - val_mae: 0.1154\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.1014 - val_loss: 0.0224 - val_mae: 0.1134\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0175 - mae: 0.1012 - val_loss: 0.0221 - val_mae: 0.1122\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.1015 - val_loss: 0.0220 - val_mae: 0.1095\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0175 - mae: 0.1017 - val_loss: 0.0219 - val_mae: 0.1101\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0173 - mae: 0.1012 - val_loss: 0.0226 - val_mae: 0.1152\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 142us/step - loss: 0.0175 - mae: 0.1010 - val_loss: 0.0224 - val_mae: 0.1099\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 147us/step - loss: 0.0172 - mae: 0.1001 - val_loss: 0.0249 - val_mae: 0.1250\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 150us/step - loss: 0.0173 - mae: 0.1008 - val_loss: 0.0221 - val_mae: 0.1115\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 138us/step - loss: 0.0171 - mae: 0.0998 - val_loss: 0.0220 - val_mae: 0.1091\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 140us/step - loss: 0.0172 - mae: 0.1008 - val_loss: 0.0216 - val_mae: 0.1101\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0170 - mae: 0.1009 - val_loss: 0.0218 - val_mae: 0.1077\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.1004 - val_loss: 0.0216 - val_mae: 0.1081\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0171 - mae: 0.1003 - val_loss: 0.0221 - val_mae: 0.1094\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 141us/step - loss: 0.0170 - mae: 0.0996 - val_loss: 0.0218 - val_mae: 0.1080\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 130us/step - loss: 0.0170 - mae: 0.0999 - val_loss: 0.0219 - val_mae: 0.1118\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 198us/step - loss: 0.0171 - mae: 0.0999 - val_loss: 0.0214 - val_mae: 0.1088\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 158us/step - loss: 0.0170 - mae: 0.0998 - val_loss: 0.0222 - val_mae: 0.1080\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0168 - mae: 0.0990 - val_loss: 0.0217 - val_mae: 0.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0169 - mae: 0.0999 - val_loss: 0.0221 - val_mae: 0.1082\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 131us/step - loss: 0.0169 - mae: 0.0998 - val_loss: 0.0217 - val_mae: 0.1093\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 122us/step - loss: 0.0169 - mae: 0.0985 - val_loss: 0.0221 - val_mae: 0.1133\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 126us/step - loss: 0.0166 - mae: 0.0982 - val_loss: 0.0221 - val_mae: 0.1099\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 118us/step - loss: 0.0169 - mae: 0.0992 - val_loss: 0.0218 - val_mae: 0.1075\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 192us/step - loss: 0.0166 - mae: 0.0986 - val_loss: 0.0216 - val_mae: 0.1114\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 195us/step - loss: 0.0165 - mae: 0.0976 - val_loss: 0.0235 - val_mae: 0.1177\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 163us/step - loss: 0.0165 - mae: 0.0987 - val_loss: 0.0230 - val_mae: 0.1173\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 134us/step - loss: 0.0165 - mae: 0.0986 - val_loss: 0.0249 - val_mae: 0.1243\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 135us/step - loss: 0.0163 - mae: 0.0977 - val_loss: 0.0221 - val_mae: 0.1147\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0167 - mae: 0.0990 - val_loss: 0.0230 - val_mae: 0.1098\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 103us/step - loss: 0.0164 - mae: 0.0972 - val_loss: 0.0215 - val_mae: 0.1081\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0166 - mae: 0.0984 - val_loss: 0.0219 - val_mae: 0.1115\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 107us/step - loss: 0.0165 - mae: 0.0980 - val_loss: 0.0216 - val_mae: 0.1087\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 107us/step - loss: 0.0166 - mae: 0.0983 - val_loss: 0.0219 - val_mae: 0.1116\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 103us/step - loss: 0.0165 - mae: 0.0974 - val_loss: 0.0225 - val_mae: 0.1085\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 102us/step - loss: 0.0166 - mae: 0.0981 - val_loss: 0.0222 - val_mae: 0.1095\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 102us/step - loss: 0.0163 - mae: 0.0975 - val_loss: 0.0225 - val_mae: 0.1088\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0163 - mae: 0.0976 - val_loss: 0.0216 - val_mae: 0.1118\n",
      "processing fold # 4\n",
      "Train on 837 samples, validate on 209 samples\n",
      "Epoch 1/80\n",
      "837/837 [==============================] - 0s 238us/step - loss: 0.0450 - mae: 0.1636 - val_loss: 0.0263 - val_mae: 0.1303\n",
      "Epoch 2/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0263 - mae: 0.1259 - val_loss: 0.0261 - val_mae: 0.1343\n",
      "Epoch 3/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0238 - mae: 0.1198 - val_loss: 0.0225 - val_mae: 0.1245\n",
      "Epoch 4/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0230 - mae: 0.1172 - val_loss: 0.0215 - val_mae: 0.1209\n",
      "Epoch 5/80\n",
      "837/837 [==============================] - 0s 103us/step - loss: 0.0222 - mae: 0.1157 - val_loss: 0.0197 - val_mae: 0.1148\n",
      "Epoch 6/80\n",
      "837/837 [==============================] - 0s 107us/step - loss: 0.0219 - mae: 0.1143 - val_loss: 0.0194 - val_mae: 0.1099\n",
      "Epoch 7/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0216 - mae: 0.1133 - val_loss: 0.0197 - val_mae: 0.1161\n",
      "Epoch 8/80\n",
      "837/837 [==============================] - 0s 104us/step - loss: 0.0211 - mae: 0.1117 - val_loss: 0.0193 - val_mae: 0.1133\n",
      "Epoch 9/80\n",
      "837/837 [==============================] - 0s 99us/step - loss: 0.0209 - mae: 0.1112 - val_loss: 0.0195 - val_mae: 0.1123\n",
      "Epoch 10/80\n",
      "837/837 [==============================] - 0s 107us/step - loss: 0.0205 - mae: 0.1094 - val_loss: 0.0190 - val_mae: 0.1111\n",
      "Epoch 11/80\n",
      "837/837 [==============================] - 0s 113us/step - loss: 0.0202 - mae: 0.1088 - val_loss: 0.0193 - val_mae: 0.1107\n",
      "Epoch 12/80\n",
      "837/837 [==============================] - 0s 103us/step - loss: 0.0200 - mae: 0.1095 - val_loss: 0.0196 - val_mae: 0.1154\n",
      "Epoch 13/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.1097 - val_loss: 0.0184 - val_mae: 0.1079\n",
      "Epoch 14/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0201 - mae: 0.1085 - val_loss: 0.0199 - val_mae: 0.1154\n",
      "Epoch 15/80\n",
      "837/837 [==============================] - 0s 98us/step - loss: 0.0200 - mae: 0.1085 - val_loss: 0.0215 - val_mae: 0.1203\n",
      "Epoch 16/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0195 - mae: 0.1072 - val_loss: 0.0194 - val_mae: 0.1095\n",
      "Epoch 17/80\n",
      "837/837 [==============================] - 0s 100us/step - loss: 0.0196 - mae: 0.1068 - val_loss: 0.0184 - val_mae: 0.1081\n",
      "Epoch 18/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0194 - mae: 0.1073 - val_loss: 0.0184 - val_mae: 0.1091\n",
      "Epoch 19/80\n",
      "837/837 [==============================] - 0s 105us/step - loss: 0.0192 - mae: 0.1067 - val_loss: 0.0190 - val_mae: 0.1144\n",
      "Epoch 20/80\n",
      "837/837 [==============================] - 0s 106us/step - loss: 0.0193 - mae: 0.1058 - val_loss: 0.0187 - val_mae: 0.1101\n",
      "Epoch 21/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0190 - mae: 0.1058 - val_loss: 0.0188 - val_mae: 0.1105\n",
      "Epoch 22/80\n",
      "837/837 [==============================] - 0s 99us/step - loss: 0.0190 - mae: 0.1057 - val_loss: 0.0190 - val_mae: 0.1099\n",
      "Epoch 23/80\n",
      "837/837 [==============================] - 0s 110us/step - loss: 0.0187 - mae: 0.1044 - val_loss: 0.0193 - val_mae: 0.1120\n",
      "Epoch 24/80\n",
      "837/837 [==============================] - 0s 99us/step - loss: 0.0186 - mae: 0.1045 - val_loss: 0.0195 - val_mae: 0.1146\n",
      "Epoch 25/80\n",
      "837/837 [==============================] - 0s 106us/step - loss: 0.0187 - mae: 0.1047 - val_loss: 0.0197 - val_mae: 0.1144\n",
      "Epoch 26/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0184 - mae: 0.1043 - val_loss: 0.0207 - val_mae: 0.1184\n",
      "Epoch 27/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0185 - mae: 0.1037 - val_loss: 0.0183 - val_mae: 0.1076\n",
      "Epoch 28/80\n",
      "837/837 [==============================] - 0s 107us/step - loss: 0.0184 - mae: 0.1042 - val_loss: 0.0184 - val_mae: 0.1101\n",
      "Epoch 29/80\n",
      "837/837 [==============================] - 0s 101us/step - loss: 0.0184 - mae: 0.1036 - val_loss: 0.0189 - val_mae: 0.1122\n",
      "Epoch 30/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.1023 - val_loss: 0.0194 - val_mae: 0.1094\n",
      "Epoch 31/80\n",
      "837/837 [==============================] - 0s 102us/step - loss: 0.0180 - mae: 0.1021 - val_loss: 0.0189 - val_mae: 0.1083\n",
      "Epoch 32/80\n",
      "837/837 [==============================] - 0s 98us/step - loss: 0.0178 - mae: 0.1015 - val_loss: 0.0184 - val_mae: 0.1095\n",
      "Epoch 33/80\n",
      "837/837 [==============================] - 0s 99us/step - loss: 0.0178 - mae: 0.1017 - val_loss: 0.0197 - val_mae: 0.1122\n",
      "Epoch 34/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0180 - mae: 0.1019 - val_loss: 0.0201 - val_mae: 0.1156\n",
      "Epoch 35/80\n",
      "837/837 [==============================] - 0s 93us/step - loss: 0.0178 - mae: 0.1020 - val_loss: 0.0194 - val_mae: 0.1122\n",
      "Epoch 36/80\n",
      "837/837 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.1012 - val_loss: 0.0177 - val_mae: 0.1058\n",
      "Epoch 37/80\n",
      "837/837 [==============================] - 0s 147us/step - loss: 0.0178 - mae: 0.1012 - val_loss: 0.0192 - val_mae: 0.1120\n",
      "Epoch 38/80\n",
      "837/837 [==============================] - 0s 137us/step - loss: 0.0177 - mae: 0.1012 - val_loss: 0.0193 - val_mae: 0.1125\n",
      "Epoch 39/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0178 - mae: 0.1012 - val_loss: 0.0192 - val_mae: 0.1118\n",
      "Epoch 40/80\n",
      "837/837 [==============================] - 0s 111us/step - loss: 0.0175 - mae: 0.1009 - val_loss: 0.0185 - val_mae: 0.1095\n",
      "Epoch 41/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0176 - mae: 0.1009 - val_loss: 0.0189 - val_mae: 0.1076\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837/837 [==============================] - 0s 122us/step - loss: 0.0174 - mae: 0.1001 - val_loss: 0.0210 - val_mae: 0.1192\n",
      "Epoch 43/80\n",
      "837/837 [==============================] - 0s 117us/step - loss: 0.0174 - mae: 0.1008 - val_loss: 0.0180 - val_mae: 0.1091\n",
      "Epoch 44/80\n",
      "837/837 [==============================] - 0s 135us/step - loss: 0.0174 - mae: 0.1005 - val_loss: 0.0186 - val_mae: 0.1101\n",
      "Epoch 45/80\n",
      "837/837 [==============================] - 0s 119us/step - loss: 0.0177 - mae: 0.1013 - val_loss: 0.0181 - val_mae: 0.1095\n",
      "Epoch 46/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0174 - mae: 0.0997 - val_loss: 0.0183 - val_mae: 0.1113\n",
      "Epoch 47/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0173 - mae: 0.0996 - val_loss: 0.0187 - val_mae: 0.1081\n",
      "Epoch 48/80\n",
      "837/837 [==============================] - 0s 129us/step - loss: 0.0171 - mae: 0.0993 - val_loss: 0.0199 - val_mae: 0.1105\n",
      "Epoch 49/80\n",
      "837/837 [==============================] - 0s 153us/step - loss: 0.0171 - mae: 0.0992 - val_loss: 0.0193 - val_mae: 0.1122\n",
      "Epoch 50/80\n",
      "837/837 [==============================] - 0s 153us/step - loss: 0.0169 - mae: 0.0984 - val_loss: 0.0181 - val_mae: 0.1064\n",
      "Epoch 51/80\n",
      "837/837 [==============================] - 0s 127us/step - loss: 0.0172 - mae: 0.0997 - val_loss: 0.0196 - val_mae: 0.1158\n",
      "Epoch 52/80\n",
      "837/837 [==============================] - 0s 124us/step - loss: 0.0172 - mae: 0.0994 - val_loss: 0.0204 - val_mae: 0.1168\n",
      "Epoch 53/80\n",
      "837/837 [==============================] - 0s 135us/step - loss: 0.0172 - mae: 0.0987 - val_loss: 0.0207 - val_mae: 0.1181\n",
      "Epoch 54/80\n",
      "837/837 [==============================] - 0s 178us/step - loss: 0.0171 - mae: 0.0985 - val_loss: 0.0180 - val_mae: 0.1081\n",
      "Epoch 55/80\n",
      "837/837 [==============================] - 0s 157us/step - loss: 0.0171 - mae: 0.0985 - val_loss: 0.0190 - val_mae: 0.1121\n",
      "Epoch 56/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0170 - mae: 0.0985 - val_loss: 0.0187 - val_mae: 0.1108\n",
      "Epoch 57/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0169 - mae: 0.0984 - val_loss: 0.0206 - val_mae: 0.1145\n",
      "Epoch 58/80\n",
      "837/837 [==============================] - 0s 115us/step - loss: 0.0171 - mae: 0.0993 - val_loss: 0.0194 - val_mae: 0.1096\n",
      "Epoch 59/80\n",
      "837/837 [==============================] - 0s 195us/step - loss: 0.0170 - mae: 0.0985 - val_loss: 0.0204 - val_mae: 0.1162\n",
      "Epoch 60/80\n",
      "837/837 [==============================] - 0s 191us/step - loss: 0.0171 - mae: 0.0987 - val_loss: 0.0181 - val_mae: 0.1070\n",
      "Epoch 61/80\n",
      "837/837 [==============================] - 0s 195us/step - loss: 0.0168 - mae: 0.0968 - val_loss: 0.0219 - val_mae: 0.1220\n",
      "Epoch 62/80\n",
      "837/837 [==============================] - 0s 146us/step - loss: 0.0169 - mae: 0.0976 - val_loss: 0.0181 - val_mae: 0.1065\n",
      "Epoch 63/80\n",
      "837/837 [==============================] - 0s 125us/step - loss: 0.0169 - mae: 0.0984 - val_loss: 0.0191 - val_mae: 0.1106\n",
      "Epoch 64/80\n",
      "837/837 [==============================] - 0s 138us/step - loss: 0.0166 - mae: 0.0971 - val_loss: 0.0204 - val_mae: 0.1153\n",
      "Epoch 65/80\n",
      "837/837 [==============================] - 0s 171us/step - loss: 0.0170 - mae: 0.0983 - val_loss: 0.0175 - val_mae: 0.1054\n",
      "Epoch 66/80\n",
      "837/837 [==============================] - 0s 139us/step - loss: 0.0166 - mae: 0.0972 - val_loss: 0.0189 - val_mae: 0.1123\n",
      "Epoch 67/80\n",
      "837/837 [==============================] - 0s 133us/step - loss: 0.0168 - mae: 0.0977 - val_loss: 0.0185 - val_mae: 0.1113\n",
      "Epoch 68/80\n",
      "837/837 [==============================] - 0s 105us/step - loss: 0.0167 - mae: 0.0975 - val_loss: 0.0185 - val_mae: 0.1069\n",
      "Epoch 69/80\n",
      "837/837 [==============================] - 0s 120us/step - loss: 0.0169 - mae: 0.0969 - val_loss: 0.0177 - val_mae: 0.1059\n",
      "Epoch 70/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0167 - mae: 0.0967 - val_loss: 0.0186 - val_mae: 0.1100\n",
      "Epoch 71/80\n",
      "837/837 [==============================] - 0s 121us/step - loss: 0.0166 - mae: 0.0967 - val_loss: 0.0185 - val_mae: 0.1085\n",
      "Epoch 72/80\n",
      "837/837 [==============================] - 0s 128us/step - loss: 0.0166 - mae: 0.0972 - val_loss: 0.0171 - val_mae: 0.1038\n",
      "Epoch 73/80\n",
      "837/837 [==============================] - 0s 108us/step - loss: 0.0164 - mae: 0.0965 - val_loss: 0.0178 - val_mae: 0.1071\n",
      "Epoch 74/80\n",
      "837/837 [==============================] - 0s 109us/step - loss: 0.0166 - mae: 0.0963 - val_loss: 0.0178 - val_mae: 0.1078\n",
      "Epoch 75/80\n",
      "837/837 [==============================] - 0s 98us/step - loss: 0.0165 - mae: 0.0957 - val_loss: 0.0192 - val_mae: 0.1092\n",
      "Epoch 76/80\n",
      "837/837 [==============================] - 0s 99us/step - loss: 0.0167 - mae: 0.0975 - val_loss: 0.0184 - val_mae: 0.1072\n",
      "Epoch 77/80\n",
      "837/837 [==============================] - 0s 100us/step - loss: 0.0169 - mae: 0.0973 - val_loss: 0.0191 - val_mae: 0.1111\n",
      "Epoch 78/80\n",
      "837/837 [==============================] - 0s 152us/step - loss: 0.0165 - mae: 0.0964 - val_loss: 0.0186 - val_mae: 0.1096\n",
      "Epoch 79/80\n",
      "837/837 [==============================] - 0s 132us/step - loss: 0.0164 - mae: 0.0953 - val_loss: 0.0242 - val_mae: 0.1285\n",
      "Epoch 80/80\n",
      "837/837 [==============================] - 0s 98us/step - loss: 0.0164 - mae: 0.0966 - val_loss: 0.0187 - val_mae: 0.1090\n"
     ]
    }
   ],
   "source": [
    "x_train_age = samples_with_age.drop([\"Age\", \"Survived\"], axis=1).values\n",
    "y_train_age = samples_with_age[\"Age\"].values\n",
    "\n",
    "number_of_epochs = 80\n",
    "number_of_folds = 5\n",
    "number_of_samples = len(x_train_age) // number_of_folds\n",
    "\n",
    "all_mae_histories = []\n",
    "all_val_mae_histories = []\n",
    "for i in range(number_of_folds):\n",
    "    print(\"processing fold #\", i)\n",
    "    partial_x_train_age = np.concatenate([x_train_age[:i*number_of_samples], x_train_age[(i+1)*number_of_samples:]])\n",
    "    parital_y_train_age = np.concatenate([y_train_age[:i*number_of_samples], y_train_age[(i+1)*number_of_samples:]])\n",
    "    \n",
    "    partial_x_validation_age = x_train_age[i*number_of_samples:(i+1)*number_of_samples]\n",
    "    partial_y_validation_age = y_train_age[i*number_of_samples:(i+1)*number_of_samples]\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(x_train_age.shape[1], activation=\"relu\", input_shape=(x_train_age.shape[1],)))\n",
    "    model.add(layers.Dense(12, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"mse\",\n",
    "                  metrics=[\"mae\"])\n",
    "\n",
    "    history = model.fit(partial_x_train_age,\n",
    "                        parital_y_train_age,\n",
    "                        epochs=number_of_epochs,\n",
    "                        batch_size=16,\n",
    "                        validation_data=(partial_x_validation_age, partial_y_validation_age))\n",
    "    all_mae_histories.append(history.history['mae'])\n",
    "    all_val_mae_histories.append(history.history['val_mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(number_of_epochs)]\n",
    "average_val_mae_history = [np.mean([x[i] for x in all_val_mae_histories]) for i in range(number_of_epochs)]\n",
    "\n",
    "epochs = range(1, number_of_epochs + 1)\n",
    "\n",
    "plt.plot(epochs, average_mae_history, \"b\", label=\"Training MAE\")\n",
    "plt.plot(epochs, average_val_mae_history, \"b\", label=\"Validation MAE\", c=\"red\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results for age prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.453024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.420812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.383475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "6                 0.0     1.0  0.453024    0.0  0.000000  0.016510     0.0   \n",
       "18                1.0     0.5  0.420812    0.0  0.000000  0.025374     0.0   \n",
       "20                1.0     1.0  0.383475    0.0  0.000000  0.014102     1.0   \n",
       "27                0.0     1.0  0.331169    0.0  0.000000  0.014102     0.0   \n",
       "29                1.0     1.0  0.259966    0.0  0.000000  0.015379     1.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1300              NaN     1.0  0.260001    0.0  0.000000  0.015070     1.0   \n",
       "1302              NaN     1.0  0.259994    0.0  0.000000  0.015127     1.0   \n",
       "1305              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1308              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0  0.017290    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "6             1.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "18            1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "20            0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "27            1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "29            0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "1300          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1302          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "6                 0.0   0.0  0.0   0.0  \n",
       "18                0.0   0.0  0.0   0.0  \n",
       "20                0.0   0.0  0.0   0.0  \n",
       "27                0.0   0.0  0.0   0.0  \n",
       "29                0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1300              0.0   0.0  0.0   0.0  \n",
       "1302              0.0   0.0  0.0   0.0  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[263 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_age = model.predict(samples_without_age.drop([\"Survived\", \"Age\"], axis=1))\n",
    "samples_without_age.loc[:,\"Age\"] = results_age\n",
    "samples_without_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>SOTON/O.Q.</th>\n",
       "      <th>2.</th>\n",
       "      <th>W./C.</th>\n",
       "      <th>STON/O</th>\n",
       "      <th>CA.</th>\n",
       "      <th>A/5</th>\n",
       "      <th>SC/PARIS</th>\n",
       "      <th>2343</th>\n",
       "      <th>CA</th>\n",
       "      <th>A/5.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass       Age  SibSp     Parch      Fare  female  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0     1.0  0.271174    0.2  0.000000  0.014151     0.0   \n",
       "2                 1.0     0.0  0.472229    0.2  0.000000  0.139136     1.0   \n",
       "3                 1.0     1.0  0.321438    0.0  0.000000  0.015469     1.0   \n",
       "4                 1.0     0.0  0.434531    0.2  0.000000  0.103644     1.0   \n",
       "5                 0.0     1.0  0.434531    0.0  0.000000  0.015713     0.0   \n",
       "...               ...     ...       ...    ...       ...       ...     ...   \n",
       "1300              NaN     1.0  0.260001    0.0  0.000000  0.015070     1.0   \n",
       "1302              NaN     1.0  0.259994    0.0  0.000000  0.015127     1.0   \n",
       "1305              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1308              NaN     1.0  0.360627    0.0  0.000000  0.015713     0.0   \n",
       "1309              NaN     1.0  0.017290    0.2  0.166667  0.043640     0.0   \n",
       "\n",
       "             male    C    Q  ...  SOTON/O.Q.   2.  W./C.  STON/O  CA.  A/5  \\\n",
       "PassengerId                  ...                                             \n",
       "1             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  1.0   \n",
       "2             0.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "3             0.0  0.0  0.0  ...         0.0  1.0    0.0     1.0  0.0  0.0   \n",
       "4             0.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "5             1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "...           ...  ...  ...  ...         ...  ...    ...     ...  ...  ...   \n",
       "1300          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1302          0.0  0.0  1.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1305          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1308          1.0  0.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "1309          1.0  1.0  0.0  ...         0.0  0.0    0.0     0.0  0.0  0.0   \n",
       "\n",
       "             SC/PARIS  2343   CA  A/5.  \n",
       "PassengerId                             \n",
       "1                 0.0   0.0  0.0   0.0  \n",
       "2                 0.0   0.0  0.0   0.0  \n",
       "3                 0.0   0.0  0.0   0.0  \n",
       "4                 0.0   0.0  0.0   0.0  \n",
       "5                 0.0   0.0  0.0   0.0  \n",
       "...               ...   ...  ...   ...  \n",
       "1300              0.0   0.0  0.0   0.0  \n",
       "1302              0.0   0.0  0.0   0.0  \n",
       "1305              0.0   0.0  0.0   0.0  \n",
       "1308              0.0   0.0  0.0   0.0  \n",
       "1309              0.0   0.0  0.0   0.0  \n",
       "\n",
       "[1309 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data_with_predicted_age = pd.concat([samples_with_age, samples_without_age])\n",
    "normalized_data_with_predicted_age.to_csv(\"normalized_data_with_predicted_age.csv\", index=True)\n",
    "normalized_data_with_predicted_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare skewness of original and predicted Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "scalar = 80\n",
    "\n",
    "plt.hist(samples_with_age.Age*scalar, range(scalar))\n",
    "plt.title(\"Original Age\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(results_age*scalar, range(scalar))\n",
    "plt.title(\"Predicted Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
